{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras\n",
    "import csv\n",
    "\n",
    "import keras_uncertainty\n",
    "from keras_uncertainty.utils import numpy_negative_log_likelihood, numpy_entropy\n",
    "from keras_uncertainty.layers import DropConnectConv2D, DropConnectDense\n",
    "from keras_uncertainty.models import MCDropoutClassifier\n",
    "from keras_uncertainty.utils import numpy_regression_nll\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_joint_space_csv_chunks(file_path):\n",
    "    data_frame = pd.read_csv(file_path, skiprows=1, header=None)\n",
    "    del data_frame[18]\n",
    "    #print(data_frame.head(10))\n",
    "    return data_frame\n",
    "\n",
    "def load_task_space_csv_chunks(file_path):\n",
    "    return pd.read_csv(file_path, skiprows=1, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_FOLDER = '/home/dfki.uni-bremen.de/bmanickavasakan/newdataset_rh5_leg/leg_5steps/'\n",
    "TEST_FOLDER = '/home/dfki.uni-bremen.de/bmanickavasakan/newdataset_rh5_leg/leg_5steps/test_4steps'\n",
    "\n",
    "X_TRAIN_FILE = os.path.join(TRAIN_FOLDER, 'leg_forwardkinematics_x.csv')\n",
    "Q_TRAIN_FILE = os.path.join(TRAIN_FOLDER, 'leg_sysstate_q.csv')\n",
    "\n",
    "X_TEST_FILE = os.path.join(TEST_FOLDER, 'leg_forwardkinematics_x.csv')\n",
    "Q_TEST_FILE = os.path.join(TEST_FOLDER, 'leg_sysstate_q.csv')\n",
    "\n",
    "x_train = load_task_space_csv_chunks(X_TRAIN_FILE)\n",
    "q_train = load_joint_space_csv_chunks(Q_TRAIN_FILE)\n",
    "\n",
    "x_test = load_task_space_csv_chunks(X_TEST_FILE)\n",
    "q_test = load_joint_space_csv_chunks(Q_TEST_FILE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    14062\n",
      "-1     1563\n",
      "Name: anamoly, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train_df = pd.DataFrame(x_train)\n",
    "q_train_df = pd.DataFrame(q_train)\n",
    "x_test_df = pd.DataFrame(x_test)\n",
    "q_test_df = pd.DataFrame(q_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "clf = IsolationForest(n_estimators=100, max_samples='auto', max_features=1, bootstrap=False, n_jobs= -1, random_state=42, verbose=0)\n",
    "clf.fit(q_train_df)\n",
    "\n",
    "pred = clf.predict(q_train_df)\n",
    "q_train_df['anamoly'] = pred\n",
    "print(q_train_df['anamoly'].value_counts())\n",
    "\n",
    "InDistribution_Q_Train = q_train_df[q_train_df['anamoly'] == 1]\n",
    "OutDistribution_Q_Train =   q_train_df[q_train_df['anamoly'] == -1]\n",
    "InDistribution_X_Train =    x_train_df[q_train_df['anamoly'] == 1]\n",
    "OutDistribution_X_Train =   x_train_df[q_train_df['anamoly'] == -1]\n",
    "\n",
    "clf_test = IsolationForest(n_estimators=100, max_samples='auto', max_features=1, bootstrap=False, n_jobs= -1, random_state=42, verbose=0)\n",
    "clf_test.fit(q_test_df)\n",
    "pred_test = clf.predict(q_test_df)\n",
    "q_test_df['anamoly'] = pred_test\n",
    "\n",
    "InDistribution_Q_Test = q_test_df[q_test_df['anamoly'] == 1]\n",
    "OutDistribution_Q_Test =q_test_df[q_test_df['anamoly'] == -1]\n",
    "InDistribution_X_Test = x_test_df[q_test_df['anamoly'] == 1]\n",
    "OutDistribution_X_Test =x_test_df[q_test_df['anamoly'] == -1]\n",
    "\n",
    "x_train_1 = InDistribution_X_Train\n",
    "q_train_1 = InDistribution_Q_Train.drop(['anamoly'], axis=1)\n",
    "x_test_1 = InDistribution_X_Test\n",
    "q_test_1 = InDistribution_Q_Test.drop(['anamoly'], axis=1)\n",
    "\n",
    "OOD_x_train = OutDistribution_X_Train\n",
    "OOD_q_train = OutDistribution_Q_Train.drop(['anamoly'], axis=1)\n",
    "OOD_x_test = OutDistribution_X_Test\n",
    "OOD_q_test = OutDistribution_Q_Test.drop(['anamoly'], axis=1)\n",
    "\n",
    "q_test = q_test.drop(['anamoly'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "q_scaler = MinMaxScaler()\n",
    "\n",
    "#In order training set\n",
    "x_train_1 = x_scaler.fit_transform(x_train_1)\n",
    "q_train_1 = q_scaler.fit_transform(q_train_1)\n",
    "\n",
    "#complete test set\n",
    "x_test = x_scaler.transform(x_test)\n",
    "q_test = q_scaler.transform(q_test)\n",
    "\n",
    "#split testing data\n",
    "IOD_x_test = x_scaler.transform(x_test_1)\n",
    "IOD_q_test = q_scaler.transform(q_test_1)\n",
    "\n",
    "OOD_x_test = x_scaler.transform(OOD_x_test)\n",
    "OOD_q_test = q_scaler.transform(OOD_q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(input_shape, output_shape):\n",
    "    def build_model(depth, width, reduction_factor):\n",
    "        model = Sequential()\n",
    "        \n",
    "\n",
    "        for i in range(depth):\n",
    "            num_neurons = max(int(width * (reduction_factor ** i)), 4)\n",
    "            if i == 0:\n",
    "                model.add(DropConnectDense(num_neurons, activation='relu', input_shape=(input_shape,), prob=0.5))\n",
    "            else:\n",
    "                model.add(DropConnectDense(num_neurons, activation='relu', prob=0.5))\n",
    "\n",
    "            model.add(BatchNormalization())\n",
    "            #num_neurons= num_neurons + 32\n",
    "            Flatten()\n",
    "\n",
    "        model.add(DropConnectDense(output_shape, activation='sigmoid', prob=0.1))\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=[\"mae\"])\n",
    "\n",
    "        return model\n",
    "    return build_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14062 samples, validate on 3790 samples\n",
      "Epoch 1/100\n",
      "14062/14062 [==============================] - 2s 137us/step - loss: 0.1392 - mae: 0.3055 - val_loss: 0.0990 - val_mae: 0.2685\n",
      "Epoch 2/100\n",
      "14062/14062 [==============================] - 1s 40us/step - loss: 0.1196 - mae: 0.2842 - val_loss: 0.0982 - val_mae: 0.2674\n",
      "Epoch 3/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.1068 - mae: 0.2692 - val_loss: 0.0956 - val_mae: 0.2639\n",
      "Epoch 4/100\n",
      "14062/14062 [==============================] - 1s 39us/step - loss: 0.0956 - mae: 0.2548 - val_loss: 0.0815 - val_mae: 0.2402\n",
      "Epoch 5/100\n",
      "14062/14062 [==============================] - 1s 40us/step - loss: 0.0869 - mae: 0.2419 - val_loss: 0.0743 - val_mae: 0.2239\n",
      "Epoch 6/100\n",
      "14062/14062 [==============================] - 1s 39us/step - loss: 0.0797 - mae: 0.2306 - val_loss: 0.0689 - val_mae: 0.2120\n",
      "Epoch 7/100\n",
      "14062/14062 [==============================] - 1s 41us/step - loss: 0.0750 - mae: 0.2224 - val_loss: 0.0650 - val_mae: 0.2055\n",
      "Epoch 8/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0718 - mae: 0.2165 - val_loss: 0.0631 - val_mae: 0.2030\n",
      "Epoch 9/100\n",
      "14062/14062 [==============================] - 1s 39us/step - loss: 0.0697 - mae: 0.2131 - val_loss: 0.0617 - val_mae: 0.1998\n",
      "Epoch 10/100\n",
      "14062/14062 [==============================] - 1s 40us/step - loss: 0.0675 - mae: 0.2091 - val_loss: 0.0600 - val_mae: 0.1971\n",
      "Epoch 11/100\n",
      "14062/14062 [==============================] - 1s 40us/step - loss: 0.0642 - mae: 0.2033 - val_loss: 0.0566 - val_mae: 0.1917\n",
      "Epoch 12/100\n",
      "14062/14062 [==============================] - 1s 39us/step - loss: 0.0610 - mae: 0.1973 - val_loss: 0.0517 - val_mae: 0.1823\n",
      "Epoch 13/100\n",
      "14062/14062 [==============================] - 1s 39us/step - loss: 0.0589 - mae: 0.1932 - val_loss: 0.0477 - val_mae: 0.1741\n",
      "Epoch 14/100\n",
      "14062/14062 [==============================] - 1s 40us/step - loss: 0.0561 - mae: 0.1882 - val_loss: 0.0471 - val_mae: 0.1731\n",
      "Epoch 15/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0542 - mae: 0.1844 - val_loss: 0.0437 - val_mae: 0.1657\n",
      "Epoch 16/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0533 - mae: 0.1825 - val_loss: 0.0436 - val_mae: 0.1658\n",
      "Epoch 17/100\n",
      "14062/14062 [==============================] - 1s 40us/step - loss: 0.0522 - mae: 0.1800 - val_loss: 0.0440 - val_mae: 0.1662\n",
      "Epoch 18/100\n",
      "14062/14062 [==============================] - 1s 39us/step - loss: 0.0511 - mae: 0.1780 - val_loss: 0.0419 - val_mae: 0.1611\n",
      "Epoch 19/100\n",
      "14062/14062 [==============================] - 1s 39us/step - loss: 0.0500 - mae: 0.1757 - val_loss: 0.0432 - val_mae: 0.1650\n",
      "Epoch 20/100\n",
      "14062/14062 [==============================] - 1s 40us/step - loss: 0.0495 - mae: 0.1752 - val_loss: 0.0422 - val_mae: 0.1623\n",
      "Epoch 21/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0481 - mae: 0.1722 - val_loss: 0.0405 - val_mae: 0.1580\n",
      "Epoch 22/100\n",
      "14062/14062 [==============================] - 1s 40us/step - loss: 0.0477 - mae: 0.1714 - val_loss: 0.0379 - val_mae: 0.1515\n",
      "Epoch 23/100\n",
      "14062/14062 [==============================] - 1s 41us/step - loss: 0.0464 - mae: 0.1689 - val_loss: 0.0371 - val_mae: 0.1501\n",
      "Epoch 24/100\n",
      "14062/14062 [==============================] - 1s 39us/step - loss: 0.0452 - mae: 0.1662 - val_loss: 0.0380 - val_mae: 0.1524\n",
      "Epoch 25/100\n",
      "14062/14062 [==============================] - 1s 41us/step - loss: 0.0435 - mae: 0.1622 - val_loss: 0.0355 - val_mae: 0.1462\n",
      "Epoch 26/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0433 - mae: 0.1612 - val_loss: 0.0330 - val_mae: 0.1380\n",
      "Epoch 27/100\n",
      "14062/14062 [==============================] - 0s 35us/step - loss: 0.0415 - mae: 0.1574 - val_loss: 0.0350 - val_mae: 0.1439\n",
      "Epoch 28/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0412 - mae: 0.1563 - val_loss: 0.0345 - val_mae: 0.1427\n",
      "Epoch 29/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0405 - mae: 0.1549 - val_loss: 0.0326 - val_mae: 0.1354\n",
      "Epoch 30/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0401 - mae: 0.1538 - val_loss: 0.0319 - val_mae: 0.1341\n",
      "Epoch 31/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0390 - mae: 0.1512 - val_loss: 0.0303 - val_mae: 0.1316\n",
      "Epoch 32/100\n",
      "14062/14062 [==============================] - 0s 35us/step - loss: 0.0385 - mae: 0.1497 - val_loss: 0.0303 - val_mae: 0.1298\n",
      "Epoch 33/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0383 - mae: 0.1489 - val_loss: 0.0324 - val_mae: 0.1346\n",
      "Epoch 34/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0380 - mae: 0.1484 - val_loss: 0.0335 - val_mae: 0.1388\n",
      "Epoch 35/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0376 - mae: 0.1471 - val_loss: 0.0277 - val_mae: 0.1228\n",
      "Epoch 36/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0368 - mae: 0.1453 - val_loss: 0.0282 - val_mae: 0.1239\n",
      "Epoch 37/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0373 - mae: 0.1462 - val_loss: 0.0291 - val_mae: 0.1263\n",
      "Epoch 38/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0368 - mae: 0.1451 - val_loss: 0.0375 - val_mae: 0.1497\n",
      "Epoch 39/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0362 - mae: 0.1432 - val_loss: 0.0326 - val_mae: 0.1344\n",
      "Epoch 40/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0360 - mae: 0.1428 - val_loss: 0.0297 - val_mae: 0.1266\n",
      "Epoch 41/100\n",
      "14062/14062 [==============================] - 0s 35us/step - loss: 0.0359 - mae: 0.1424 - val_loss: 0.0342 - val_mae: 0.1394\n",
      "Epoch 42/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0355 - mae: 0.1413 - val_loss: 0.0339 - val_mae: 0.1396\n",
      "Epoch 43/100\n",
      "14062/14062 [==============================] - 0s 36us/step - loss: 0.0351 - mae: 0.1411 - val_loss: 0.0317 - val_mae: 0.1346\n",
      "Epoch 44/100\n",
      "14062/14062 [==============================] - 0s 36us/step - loss: 0.0357 - mae: 0.1420 - val_loss: 0.0308 - val_mae: 0.1313\n",
      "Epoch 45/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0352 - mae: 0.1410 - val_loss: 0.0309 - val_mae: 0.1330\n",
      "Epoch 46/100\n",
      "14062/14062 [==============================] - 0s 35us/step - loss: 0.0345 - mae: 0.1391 - val_loss: 0.0298 - val_mae: 0.1285\n",
      "Epoch 47/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0347 - mae: 0.1398 - val_loss: 0.0303 - val_mae: 0.1291\n",
      "Epoch 48/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0342 - mae: 0.1385 - val_loss: 0.0330 - val_mae: 0.1371\n",
      "Epoch 49/100\n",
      "14062/14062 [==============================] - 0s 34us/step - loss: 0.0338 - mae: 0.1376 - val_loss: 0.0346 - val_mae: 0.1425\n",
      "Epoch 50/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0339 - mae: 0.1375 - val_loss: 0.0338 - val_mae: 0.1397\n",
      "Epoch 51/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0337 - mae: 0.1374 - val_loss: 0.0336 - val_mae: 0.1383\n",
      "Epoch 52/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0336 - mae: 0.1370 - val_loss: 0.0319 - val_mae: 0.1331\n",
      "Epoch 53/100\n",
      "14062/14062 [==============================] - 1s 39us/step - loss: 0.0338 - mae: 0.1376 - val_loss: 0.0312 - val_mae: 0.1306\n",
      "Epoch 54/100\n",
      "14062/14062 [==============================] - 0s 35us/step - loss: 0.0331 - mae: 0.1358 - val_loss: 0.0322 - val_mae: 0.1352\n",
      "Epoch 55/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0331 - mae: 0.1363 - val_loss: 0.0363 - val_mae: 0.1435\n",
      "Epoch 56/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0328 - mae: 0.1353 - val_loss: 0.0304 - val_mae: 0.1274\n",
      "Epoch 57/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0325 - mae: 0.1349 - val_loss: 0.0380 - val_mae: 0.1495\n",
      "Epoch 58/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0321 - mae: 0.1345 - val_loss: 0.0337 - val_mae: 0.1407\n",
      "Epoch 59/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0331 - mae: 0.1366 - val_loss: 0.0303 - val_mae: 0.1304\n",
      "Epoch 60/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0317 - mae: 0.1335 - val_loss: 0.0351 - val_mae: 0.1441\n",
      "Epoch 61/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0318 - mae: 0.1337 - val_loss: 0.0359 - val_mae: 0.1463\n",
      "Epoch 62/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0319 - mae: 0.1341 - val_loss: 0.0297 - val_mae: 0.1319\n",
      "Epoch 63/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0311 - mae: 0.1320 - val_loss: 0.0335 - val_mae: 0.1396\n",
      "Epoch 64/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0312 - mae: 0.1326 - val_loss: 0.0334 - val_mae: 0.1412\n",
      "Epoch 65/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0311 - mae: 0.1325 - val_loss: 0.0297 - val_mae: 0.1303\n",
      "Epoch 66/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0315 - mae: 0.1334 - val_loss: 0.0311 - val_mae: 0.1352\n",
      "Epoch 67/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0310 - mae: 0.1327 - val_loss: 0.0343 - val_mae: 0.1425\n",
      "Epoch 68/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0304 - mae: 0.1309 - val_loss: 0.0358 - val_mae: 0.1452\n",
      "Epoch 69/100\n",
      "14062/14062 [==============================] - 1s 39us/step - loss: 0.0303 - mae: 0.1310 - val_loss: 0.0342 - val_mae: 0.1437\n",
      "Epoch 70/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0297 - mae: 0.1296 - val_loss: 0.0331 - val_mae: 0.1396\n",
      "Epoch 71/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0303 - mae: 0.1313 - val_loss: 0.0341 - val_mae: 0.1430\n",
      "Epoch 72/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0298 - mae: 0.1301 - val_loss: 0.0319 - val_mae: 0.1378\n",
      "Epoch 73/100\n",
      "14062/14062 [==============================] - 0s 36us/step - loss: 0.0297 - mae: 0.1302 - val_loss: 0.0265 - val_mae: 0.1245\n",
      "Epoch 74/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0290 - mae: 0.1288 - val_loss: 0.0257 - val_mae: 0.1224\n",
      "Epoch 75/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0287 - mae: 0.1279 - val_loss: 0.0305 - val_mae: 0.1338\n",
      "Epoch 76/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0286 - mae: 0.1281 - val_loss: 0.0296 - val_mae: 0.1312\n",
      "Epoch 77/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0286 - mae: 0.1277 - val_loss: 0.0303 - val_mae: 0.1340\n",
      "Epoch 78/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0275 - mae: 0.1255 - val_loss: 0.0254 - val_mae: 0.1225\n",
      "Epoch 79/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0281 - mae: 0.1268 - val_loss: 0.0249 - val_mae: 0.1204\n",
      "Epoch 80/100\n",
      "14062/14062 [==============================] - 0s 35us/step - loss: 0.0277 - mae: 0.1260 - val_loss: 0.0326 - val_mae: 0.1392\n",
      "Epoch 81/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0272 - mae: 0.1246 - val_loss: 0.0295 - val_mae: 0.1333\n",
      "Epoch 82/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0276 - mae: 0.1258 - val_loss: 0.0317 - val_mae: 0.1372\n",
      "Epoch 83/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0275 - mae: 0.1254 - val_loss: 0.0249 - val_mae: 0.1199\n",
      "Epoch 84/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0269 - mae: 0.1241 - val_loss: 0.0294 - val_mae: 0.1316\n",
      "Epoch 85/100\n",
      "14062/14062 [==============================] - 1s 38us/step - loss: 0.0267 - mae: 0.1234 - val_loss: 0.0271 - val_mae: 0.1257\n",
      "Epoch 86/100\n",
      "14062/14062 [==============================] - 1s 39us/step - loss: 0.0265 - mae: 0.1226 - val_loss: 0.0280 - val_mae: 0.1284\n",
      "Epoch 87/100\n",
      "14062/14062 [==============================] - 1s 40us/step - loss: 0.0261 - mae: 0.1216 - val_loss: 0.0333 - val_mae: 0.1402\n",
      "Epoch 88/100\n",
      "14062/14062 [==============================] - 1s 40us/step - loss: 0.0267 - mae: 0.1231 - val_loss: 0.0348 - val_mae: 0.1442\n",
      "Epoch 89/100\n",
      "14062/14062 [==============================] - 1s 40us/step - loss: 0.0257 - mae: 0.1208 - val_loss: 0.0330 - val_mae: 0.1410\n",
      "Epoch 90/100\n",
      "14062/14062 [==============================] - 1s 42us/step - loss: 0.0267 - mae: 0.1228 - val_loss: 0.0295 - val_mae: 0.1322\n",
      "Epoch 91/100\n",
      "14062/14062 [==============================] - 0s 35us/step - loss: 0.0258 - mae: 0.1207 - val_loss: 0.0302 - val_mae: 0.1337\n",
      "Epoch 92/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0255 - mae: 0.1200 - val_loss: 0.0337 - val_mae: 0.1434\n",
      "Epoch 93/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0261 - mae: 0.1217 - val_loss: 0.0281 - val_mae: 0.1296\n",
      "Epoch 94/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0261 - mae: 0.1212 - val_loss: 0.0322 - val_mae: 0.1381\n",
      "Epoch 95/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0256 - mae: 0.1201 - val_loss: 0.0327 - val_mae: 0.1376\n",
      "Epoch 96/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0255 - mae: 0.1195 - val_loss: 0.0300 - val_mae: 0.1324\n",
      "Epoch 97/100\n",
      "14062/14062 [==============================] - 1s 37us/step - loss: 0.0254 - mae: 0.1194 - val_loss: 0.0413 - val_mae: 0.1570\n",
      "Epoch 98/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0249 - mae: 0.1179 - val_loss: 0.0368 - val_mae: 0.1483\n",
      "Epoch 99/100\n",
      "14062/14062 [==============================] - 0s 36us/step - loss: 0.0253 - mae: 0.1188 - val_loss: 0.0304 - val_mae: 0.1322\n",
      "Epoch 100/100\n",
      "14062/14062 [==============================] - 1s 36us/step - loss: 0.0254 - mae: 0.1194 - val_loss: 0.0271 - val_mae: 0.1261\n"
     ]
    }
   ],
   "source": [
    "HYPERPARAMETERS = {'depth': 6, 'width': 64, 'reduction_factor':  0.9}\n",
    "import tensorflow as tf\n",
    "with tf.device('/cpu:0'):\n",
    "    model = model_builder(9, 18)(**HYPERPARAMETERS)\n",
    "    hist = model.fit(x_train_1, q_train_1, epochs = 100, batch_size = 128, verbose = 1, validation_data=(IOD_x_test, IOD_q_test))\n",
    "    model.save(\"ik-rh5-leg-5steps_dropconnect_OOD.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (200,) and (100,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c9a61375ff60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(hist.history['loss'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'MAE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2840\u001b[0m     return gca().plot(\n\u001b[1;32m   2841\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2842\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \"\"\"\n\u001b[1;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (200,) and (100,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch  = list(range(0, 200, 1))\n",
    "#print(epoch)\n",
    "#print(hist.history['loss'])\n",
    "plt.figure()\n",
    "plt.plot( epoch, hist.history['loss'],     label = 'Loss')\n",
    "plt.plot( epoch, hist.history['mae'],      label = 'MAE')\n",
    "plt.plot( epoch, hist.history['val_loss'], label = 'val_loss')\n",
    "plt.plot( epoch, hist.history['val_mae'],  label = 'val_mae')\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MAE: 0.10467\n",
      "Q feature 0 has unnorm MAE: 0.1965 (Range -0.7330 to 0.4398) normalized MAE: 0.1675\n",
      "Q feature 1 has unnorm MAE: 0.2385 (Range -0.3840 to 0.5792) normalized MAE: 0.2476\n",
      "Q feature 2 has unnorm MAE: 0.0767 (Range -0.8200 to -0.0680) normalized MAE: 0.1020\n",
      "Q feature 3 has unnorm MAE: 0.0764 (Range -0.8381 to -0.0792) normalized MAE: 0.1007\n",
      "Q feature 4 has unnorm MAE: 0.0085 (Range 0.0070 to 0.0907) normalized MAE: 0.1020\n",
      "Q feature 5 has unnorm MAE: 0.0440 (Range 0.0000 to 1.0000) normalized MAE: 0.0440\n",
      "Q feature 6 has unnorm MAE: 0.0053 (Range -0.0822 to 0.0000) normalized MAE: 0.0643\n",
      "Q feature 7 has unnorm MAE: 0.0033 (Range 0.0000 to 0.0782) normalized MAE: 0.0420\n",
      "Q feature 8 has unnorm MAE: 0.1689 (Range -0.7850 to 0.4710) normalized MAE: 0.1345\n",
      "Q feature 9 has unnorm MAE: 0.1000 (Range -0.7850 to 0.4710) normalized MAE: 0.0796\n",
      "Q feature 10 has unnorm MAE: 0.1725 (Range -0.5905 to 0.8678) normalized MAE: 0.1183\n",
      "Q feature 11 has unnorm MAE: 0.1818 (Range -0.5744 to 0.9404) normalized MAE: 0.1201\n",
      "Q feature 12 has unnorm MAE: 0.0222 (Range -0.0783 to 0.1694) normalized MAE: 0.0897\n",
      "Q feature 13 has unnorm MAE: 0.0092 (Range -0.0687 to 0.0186) normalized MAE: 0.1057\n",
      "Q feature 14 has unnorm MAE: 0.0098 (Range -0.0468 to 0.0678) normalized MAE: 0.0857\n",
      "Q feature 15 has unnorm MAE: 0.0224 (Range -0.1222 to 0.1126) normalized MAE: 0.0955\n",
      "Q feature 16 has unnorm MAE: 0.0114 (Range -0.0687 to 0.0249) normalized MAE: 0.1216\n",
      "Q feature 17 has unnorm MAE: 0.0075 (Range -0.0510 to 0.0678) normalized MAE: 0.0633\n"
     ]
    }
   ],
   "source": [
    "q_pred = model.predict(x_test, verbose=0)\n",
    "q_unnorm = q_scaler.inverse_transform(q_test)\n",
    "q_pred_unnorm = q_scaler.inverse_transform(q_pred)\n",
    "\n",
    "global_mae = mean_absolute_error(q_test, q_pred)\n",
    "\n",
    "print(\"Testing MAE: {:.5f}\".format(global_mae))\n",
    "\n",
    "# Compute MAE for each output independently.\n",
    "for i in range(q_test.shape[1]):\n",
    "    norm_mae_i = mean_absolute_error(q_test[:, i], q_pred[:, i])\n",
    "    mae_i = mean_absolute_error(q_unnorm[:, i], q_pred_unnorm[:, i])\n",
    "    print(\"Q feature {} has unnorm MAE: {:.4f} (Range {:.4f} to {:.4f}) normalized MAE: {:.4f}\".format(i, mae_i, q_scaler.data_min_[i], q_scaler.data_max_[i], norm_mae_i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MAE: 0.28742\n",
      "NLL: 6.67680\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras_uncertainty.models import MCDropoutRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def test_mcdropconnect_regressor(x_test_values, q_test_values, model, data_scaler):   \n",
    "    mc_model = MCDropoutRegressor(model)\n",
    "    inp = x_test_values  \n",
    "    \n",
    "    mean, std = mc_model.predict(inp, num_samples = 10)\n",
    "    \n",
    "    q_pred_unnormalised = data_scaler.inverse_transform(mean)\n",
    "    \n",
    "    #q_sd_unnromalised = data_scaler.inverse_transform(std)\n",
    "    \n",
    "    global_mae = mean_absolute_error(q_test_values, mean)\n",
    "\n",
    "    print(\"Testing MAE: {:.5f}\".format(global_mae))\n",
    "\n",
    "    return q_pred_unnormalised, std\n",
    "\n",
    "mean_1, std_1 = test_mcdropconnect_regressor(x_test, q_test, model, q_scaler)\n",
    "\n",
    "q_test_unorm = q_scaler.inverse_transform(q_test)\n",
    "\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_1, std_1**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MAE: 0.25237\n",
      "NLL: 6.06231\n"
     ]
    }
   ],
   "source": [
    "mean_test_IOD, sd_test_IOD = test_mcdropconnect_regressor(IOD_x_test, IOD_q_test, model, q_scaler)\n",
    "q_test_unorm = q_scaler.inverse_transform(IOD_q_test)\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_test_IOD, sd_test_IOD**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MAE: 0.35367\n",
      "NLL: 6.85776\n"
     ]
    }
   ],
   "source": [
    "mean_test_OOD, sd_test_OOD = test_mcdropconnect_regressor(OOD_x_test, OOD_q_test, model, q_scaler)\n",
    "q_test_unorm = q_scaler.inverse_transform(OOD_q_test)\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_test_OOD, sd_test_OOD**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_no = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sd_test_IOD_df = pd.DataFrame(sd_test_IOD)\n",
    "sd_test_OOD_df = pd.DataFrame(sd_test_OOD)\n",
    "new_scores = np.concatenate([sd_test_IOD_df[col_no], sd_test_OOD_df[col_no]], axis=0)\n",
    "minmaxscaler = MinMaxScaler()\n",
    "new_scores_scaled = minmaxscaler.fit_transform(new_scores.reshape(-1, 1))\n",
    "\n",
    "new_labels = np.concatenate([np.zeros_like(sd_test_IOD_df[col_no]), np.ones_like(sd_test_OOD_df[col_no])], axis=0)\n",
    "histogram_df = pd.DataFrame(new_scores_scaled, new_labels)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "a_heights, a_bins = np.histogram(sd_test_IOD_df[col_no].values.reshape(-1, 1), density=True)\n",
    "b_heights, b_bins = np.histogram(sd_test_OOD_df[col_no].values.reshape(-1, 1), bins=a_bins, density=True)\n",
    "\n",
    "width = (a_bins[1] - a_bins[0])/3\n",
    "\n",
    "ax.bar(a_bins[:-1], a_heights, width = width, facecolor='blue',label=\"IOD SD\")\n",
    "ax.bar(b_bins[:-1]+width, b_heights, width = width, facecolor='red', label=\"OOD SD\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Standard Deviation\")\n",
    "ax.set_ylabel(\"Normailsed Density of Samples\")\n",
    "fig.savefig(\"density_vs_sd_dropconnect_iso_split_col_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5018185110455792\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "norm_scores = new_scores - min(new_scores) / (max(new_scores) - min(new_scores))\n",
    "\n",
    "auc = roc_auc_score(new_labels, new_scores)\n",
    "fpr, tpr, threshs = roc_curve(new_labels, norm_scores, drop_intermediate=True)\n",
    "print(auc)\n",
    "plt.xlabel('FPR', fontsize=13)\n",
    "plt.ylabel('TPR', fontsize=13)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.savefig(\"auc_dropconnect_iso_split_col_2.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
