{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras\n",
    "import csv\n",
    "\n",
    "import keras_uncertainty\n",
    "from keras_uncertainty.utils import numpy_negative_log_likelihood, numpy_entropy\n",
    "from keras_uncertainty.layers import DropConnectConv2D, DropConnectDense\n",
    "from keras_uncertainty.models import MCDropoutClassifier\n",
    "from keras_uncertainty.utils import numpy_regression_nll\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_joint_space_csv_chunks(file_path):\n",
    "    data_frame = pd.read_csv(file_path, skiprows=1, header=None)\n",
    "    del data_frame[18]\n",
    "    #print(data_frame.head(10))\n",
    "    return data_frame\n",
    "\n",
    "def load_task_space_csv_chunks(file_path):\n",
    "    return pd.read_csv(file_path, skiprows=1, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_FOLDER = '/home/dfki.uni-bremen.de/bmanickavasakan/newdataset_rh5_leg/leg_5steps/'\n",
    "TEST_FOLDER = '/home/dfki.uni-bremen.de/bmanickavasakan/newdataset_rh5_leg/leg_5steps/test_4steps'\n",
    "\n",
    "X_TRAIN_FILE = os.path.join(TRAIN_FOLDER, 'leg_forwardkinematics_x.csv')\n",
    "Q_TRAIN_FILE = os.path.join(TRAIN_FOLDER, 'leg_sysstate_q.csv')\n",
    "\n",
    "X_TEST_FILE = os.path.join(TEST_FOLDER, 'leg_forwardkinematics_x.csv')\n",
    "Q_TEST_FILE = os.path.join(TEST_FOLDER, 'leg_sysstate_q.csv')\n",
    "\n",
    "x_train = load_task_space_csv_chunks(X_TRAIN_FILE)\n",
    "q_train = load_joint_space_csv_chunks(Q_TRAIN_FILE)\n",
    "\n",
    "x_test = load_task_space_csv_chunks(X_TEST_FILE)\n",
    "q_test = load_joint_space_csv_chunks(Q_TEST_FILE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9119140506494964 -0.5558160506494813\n",
      "//////////////////////\n",
      "(13750, 9) (1875, 9) (3840, 9) (256, 9)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Standard deviation based data splitting\n",
    "\n",
    "We consider the Q features and use the feature with the \n",
    "\n",
    "highest SD for dividing the dataset\n",
    "'''\n",
    "\n",
    "stats_q_train = pd.DataFrame()\n",
    "stats_q_train[\"Mean\"] = q_train.mean()\n",
    "stats_q_train[\"Var\"] = q_train.var()\n",
    "stats_q_train[\"STD\"] = q_train.std()\n",
    "stats_q_train[\"OneSigmaMax\"] = stats_q_train[\"Mean\"] + stats_q_train[\"STD\"]\n",
    "stats_q_train[\"OneSigmaMin\"] = stats_q_train[\"Mean\"] - stats_q_train[\"STD\"]\n",
    "stats_q_train.T\n",
    "\n",
    "max_std = stats_q_train[\"STD\"].max()\n",
    "colomn_max_std = stats_q_train[\"STD\"].idxmax()\n",
    "\n",
    "maximum = stats_q_train.loc[colomn_max_std, \"Mean\"] + (1.5 * max_std)\n",
    "minimum = stats_q_train.loc[colomn_max_std, \"Mean\"] - (1.5 * max_std)\n",
    "print(maximum, minimum)\n",
    "\n",
    "InDistribution_Q_Train = q_train[q_train[colomn_max_std].le(maximum) & q_train[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_Q_Train = q_train[q_train[colomn_max_std].ge(maximum) | q_train[colomn_max_std].le(minimum)]\n",
    "InDistribution_X_Train = x_train[q_train[colomn_max_std].le(maximum) & q_train[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_X_Train = x_train[q_train[colomn_max_std].ge(maximum) | q_train[colomn_max_std].le(minimum)]\n",
    "\n",
    "InDistribution_Q_Test = q_test[q_test[colomn_max_std].le(maximum) & q_test[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_Q_Test = q_test[q_test[colomn_max_std].ge(maximum) | q_test[colomn_max_std].le(minimum)]\n",
    "InDistribution_X_Test = x_test[q_test[colomn_max_std].le(maximum) & q_test[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_X_Test = x_test[q_test[colomn_max_std].ge(maximum) | q_test[colomn_max_std].le(minimum)]\n",
    "\n",
    "x_train_1 = InDistribution_X_Train\n",
    "q_train_1 = InDistribution_Q_Train\n",
    "x_test_1 = InDistribution_X_Test\n",
    "q_test_1 = InDistribution_Q_Test\n",
    "\n",
    "OOD_x_train = OutDistribution_X_Train\n",
    "OOD_q_train = OutDistribution_Q_Train\n",
    "OOD_x_test = OutDistribution_X_Test\n",
    "OOD_q_test = OutDistribution_Q_Test\n",
    "\n",
    "print(\"//////////////////////\")\n",
    "print(x_train_1.shape, OOD_x_train.shape, x_test_1.shape, OOD_x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "q_scaler = MinMaxScaler()\n",
    "\n",
    "#In order training set\n",
    "x_train_1 = x_scaler.fit_transform(x_train_1)\n",
    "q_train_1 = q_scaler.fit_transform(q_train_1)\n",
    "\n",
    "#complete test set\n",
    "x_test = x_scaler.transform(x_test)\n",
    "q_test = q_scaler.transform(q_test)\n",
    "\n",
    "#split testing data\n",
    "IOD_x_test = x_scaler.transform(x_test_1)\n",
    "IOD_q_test = q_scaler.transform(q_test_1)\n",
    "\n",
    "OOD_x_test = x_scaler.transform(OOD_x_test)\n",
    "OOD_q_test = q_scaler.transform(OOD_q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropconnectProb = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(input_shape, output_shape):\n",
    "    def build_model(depth, width, reduction_factor):\n",
    "        model = Sequential()\n",
    "        \n",
    "\n",
    "        for i in range(depth):\n",
    "            num_neurons = max(int(width * (reduction_factor ** i)), 4)\n",
    "            if i == 0:\n",
    "                model.add(DropConnectDense(num_neurons, activation='relu', input_shape=(input_shape,), prob=dropconnectProb))\n",
    "            else:\n",
    "                model.add(DropConnectDense(num_neurons, activation='relu', prob=dropconnectProb))\n",
    "\n",
    "            model.add(BatchNormalization())\n",
    "            #num_neurons= num_neurons + 32\n",
    "            Flatten()\n",
    "\n",
    "        model.add(DropConnectDense(output_shape, activation='sigmoid', prob=dropconnectProb))\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=[\"mae\"])\n",
    "\n",
    "        return model\n",
    "    return build_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13750 samples, validate on 3840 samples\n",
      "Epoch 1/100\n",
      "13750/13750 [==============================] - 3s 252us/step - loss: 0.1681 - mae: 0.3351 - val_loss: 0.1098 - val_mae: 0.2859\n",
      "Epoch 2/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.1412 - mae: 0.3085 - val_loss: 0.1080 - val_mae: 0.2828\n",
      "Epoch 3/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.1233 - mae: 0.2902 - val_loss: 0.1040 - val_mae: 0.2782\n",
      "Epoch 4/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.1093 - mae: 0.2745 - val_loss: 0.0933 - val_mae: 0.2600\n",
      "Epoch 5/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0992 - mae: 0.2617 - val_loss: 0.0868 - val_mae: 0.2444\n",
      "Epoch 6/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0934 - mae: 0.2531 - val_loss: 0.0849 - val_mae: 0.2390\n",
      "Epoch 7/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0892 - mae: 0.2466 - val_loss: 0.0825 - val_mae: 0.2348\n",
      "Epoch 8/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0863 - mae: 0.2417 - val_loss: 0.0791 - val_mae: 0.2294\n",
      "Epoch 9/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0834 - mae: 0.2368 - val_loss: 0.0767 - val_mae: 0.2246\n",
      "Epoch 10/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0810 - mae: 0.2325 - val_loss: 0.0743 - val_mae: 0.2202\n",
      "Epoch 11/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0788 - mae: 0.2284 - val_loss: 0.0717 - val_mae: 0.2157\n",
      "Epoch 12/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0774 - mae: 0.2258 - val_loss: 0.0714 - val_mae: 0.2151\n",
      "Epoch 13/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0759 - mae: 0.2230 - val_loss: 0.0696 - val_mae: 0.2123\n",
      "Epoch 14/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0749 - mae: 0.2212 - val_loss: 0.0683 - val_mae: 0.2100\n",
      "Epoch 15/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0741 - mae: 0.2195 - val_loss: 0.0679 - val_mae: 0.2089\n",
      "Epoch 16/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0733 - mae: 0.2181 - val_loss: 0.0664 - val_mae: 0.2065\n",
      "Epoch 17/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0710 - mae: 0.2146 - val_loss: 0.0636 - val_mae: 0.2012\n",
      "Epoch 18/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0688 - mae: 0.2108 - val_loss: 0.0598 - val_mae: 0.1942\n",
      "Epoch 19/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0656 - mae: 0.2052 - val_loss: 0.0575 - val_mae: 0.1901\n",
      "Epoch 20/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0639 - mae: 0.2017 - val_loss: 0.0577 - val_mae: 0.1900\n",
      "Epoch 21/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0619 - mae: 0.1981 - val_loss: 0.0529 - val_mae: 0.1804\n",
      "Epoch 22/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0607 - mae: 0.1960 - val_loss: 0.0531 - val_mae: 0.1803\n",
      "Epoch 23/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0607 - mae: 0.1956 - val_loss: 0.0518 - val_mae: 0.1783\n",
      "Epoch 24/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0590 - mae: 0.1927 - val_loss: 0.0566 - val_mae: 0.1878\n",
      "Epoch 25/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0585 - mae: 0.1917 - val_loss: 0.0517 - val_mae: 0.1779\n",
      "Epoch 26/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0589 - mae: 0.1921 - val_loss: 0.0516 - val_mae: 0.1773\n",
      "Epoch 27/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0571 - mae: 0.1891 - val_loss: 0.0524 - val_mae: 0.1790\n",
      "Epoch 28/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0568 - mae: 0.1881 - val_loss: 0.0529 - val_mae: 0.1799\n",
      "Epoch 29/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0567 - mae: 0.1877 - val_loss: 0.0529 - val_mae: 0.1794\n",
      "Epoch 30/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0564 - mae: 0.1874 - val_loss: 0.0533 - val_mae: 0.1798\n",
      "Epoch 31/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0558 - mae: 0.1860 - val_loss: 0.0538 - val_mae: 0.1810\n",
      "Epoch 32/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0555 - mae: 0.1854 - val_loss: 0.0546 - val_mae: 0.1821\n",
      "Epoch 33/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0550 - mae: 0.1845 - val_loss: 0.0613 - val_mae: 0.1920\n",
      "Epoch 34/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0554 - mae: 0.1852 - val_loss: 0.0546 - val_mae: 0.1811\n",
      "Epoch 35/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0550 - mae: 0.1843 - val_loss: 0.0541 - val_mae: 0.1803\n",
      "Epoch 36/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0550 - mae: 0.1844 - val_loss: 0.0528 - val_mae: 0.1775\n",
      "Epoch 37/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0543 - mae: 0.1828 - val_loss: 0.0561 - val_mae: 0.1831\n",
      "Epoch 38/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0540 - mae: 0.1822 - val_loss: 0.0562 - val_mae: 0.1834\n",
      "Epoch 39/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0536 - mae: 0.1814 - val_loss: 0.0596 - val_mae: 0.1877\n",
      "Epoch 40/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0534 - mae: 0.1808 - val_loss: 0.0578 - val_mae: 0.1853\n",
      "Epoch 41/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0532 - mae: 0.1807 - val_loss: 0.0546 - val_mae: 0.1801\n",
      "Epoch 42/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0529 - mae: 0.1798 - val_loss: 0.0539 - val_mae: 0.1781\n",
      "Epoch 43/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0529 - mae: 0.1798 - val_loss: 0.0562 - val_mae: 0.1823\n",
      "Epoch 44/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0529 - mae: 0.1799 - val_loss: 0.0567 - val_mae: 0.1830\n",
      "Epoch 45/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0526 - mae: 0.1788 - val_loss: 0.0560 - val_mae: 0.1821\n",
      "Epoch 46/100\n",
      "13750/13750 [==============================] - 1s 51us/step - loss: 0.0523 - mae: 0.1784 - val_loss: 0.0575 - val_mae: 0.1848\n",
      "Epoch 47/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0519 - mae: 0.1777 - val_loss: 0.0571 - val_mae: 0.1838\n",
      "Epoch 48/100\n",
      "13750/13750 [==============================] - 1s 55us/step - loss: 0.0524 - mae: 0.1786 - val_loss: 0.0544 - val_mae: 0.1799\n",
      "Epoch 49/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0516 - mae: 0.1774 - val_loss: 0.0538 - val_mae: 0.1788\n",
      "Epoch 50/100\n",
      "13750/13750 [==============================] - 1s 56us/step - loss: 0.0513 - mae: 0.1767 - val_loss: 0.0515 - val_mae: 0.1751\n",
      "Epoch 51/100\n",
      "13750/13750 [==============================] - 1s 56us/step - loss: 0.0511 - mae: 0.1761 - val_loss: 0.0543 - val_mae: 0.1798\n",
      "Epoch 52/100\n",
      "13750/13750 [==============================] - 1s 55us/step - loss: 0.0503 - mae: 0.1744 - val_loss: 0.0533 - val_mae: 0.1782\n",
      "Epoch 53/100\n",
      "13750/13750 [==============================] - 1s 56us/step - loss: 0.0505 - mae: 0.1747 - val_loss: 0.0530 - val_mae: 0.1771\n",
      "Epoch 54/100\n",
      "13750/13750 [==============================] - 1s 55us/step - loss: 0.0500 - mae: 0.1741 - val_loss: 0.0527 - val_mae: 0.1755\n",
      "Epoch 55/100\n",
      "13750/13750 [==============================] - 1s 56us/step - loss: 0.0504 - mae: 0.1744 - val_loss: 0.0507 - val_mae: 0.1729\n",
      "Epoch 56/100\n",
      "13750/13750 [==============================] - 1s 59us/step - loss: 0.0497 - mae: 0.1734 - val_loss: 0.0510 - val_mae: 0.1740\n",
      "Epoch 57/100\n",
      "13750/13750 [==============================] - 1s 60us/step - loss: 0.0497 - mae: 0.1733 - val_loss: 0.0508 - val_mae: 0.1743\n",
      "Epoch 58/100\n",
      "13750/13750 [==============================] - 1s 57us/step - loss: 0.0489 - mae: 0.1714 - val_loss: 0.0542 - val_mae: 0.1816\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13750/13750 [==============================] - 1s 56us/step - loss: 0.0484 - mae: 0.1709 - val_loss: 0.0531 - val_mae: 0.1789\n",
      "Epoch 60/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0493 - mae: 0.1723 - val_loss: 0.0537 - val_mae: 0.1799\n",
      "Epoch 61/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0484 - mae: 0.1706 - val_loss: 0.0564 - val_mae: 0.1850\n",
      "Epoch 62/100\n",
      "13750/13750 [==============================] - 1s 56us/step - loss: 0.0482 - mae: 0.1702 - val_loss: 0.0487 - val_mae: 0.1714\n",
      "Epoch 63/100\n",
      "13750/13750 [==============================] - 1s 55us/step - loss: 0.0479 - mae: 0.1701 - val_loss: 0.0489 - val_mae: 0.1715\n",
      "Epoch 64/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0474 - mae: 0.1688 - val_loss: 0.0461 - val_mae: 0.1671\n",
      "Epoch 65/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0471 - mae: 0.1685 - val_loss: 0.0444 - val_mae: 0.1638\n",
      "Epoch 66/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0460 - mae: 0.1662 - val_loss: 0.0439 - val_mae: 0.1628\n",
      "Epoch 67/100\n",
      "13750/13750 [==============================] - 1s 55us/step - loss: 0.0461 - mae: 0.1663 - val_loss: 0.0476 - val_mae: 0.1699\n",
      "Epoch 68/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0452 - mae: 0.1645 - val_loss: 0.0443 - val_mae: 0.1635\n",
      "Epoch 69/100\n",
      "13750/13750 [==============================] - 1s 55us/step - loss: 0.0451 - mae: 0.1641 - val_loss: 0.0447 - val_mae: 0.1646\n",
      "Epoch 70/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0447 - mae: 0.1634 - val_loss: 0.0437 - val_mae: 0.1621\n",
      "Epoch 71/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0438 - mae: 0.1616 - val_loss: 0.0458 - val_mae: 0.1660\n",
      "Epoch 72/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0444 - mae: 0.1622 - val_loss: 0.0445 - val_mae: 0.1636\n",
      "Epoch 73/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0438 - mae: 0.1612 - val_loss: 0.0487 - val_mae: 0.1718\n",
      "Epoch 74/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0427 - mae: 0.1584 - val_loss: 0.0449 - val_mae: 0.1645\n",
      "Epoch 75/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0429 - mae: 0.1592 - val_loss: 0.0510 - val_mae: 0.1765\n",
      "Epoch 76/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0432 - mae: 0.1595 - val_loss: 0.0474 - val_mae: 0.1678\n",
      "Epoch 77/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0419 - mae: 0.1567 - val_loss: 0.0525 - val_mae: 0.1766\n",
      "Epoch 78/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0424 - mae: 0.1578 - val_loss: 0.0428 - val_mae: 0.1591\n",
      "Epoch 79/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0418 - mae: 0.1562 - val_loss: 0.0502 - val_mae: 0.1748\n",
      "Epoch 80/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0416 - mae: 0.1556 - val_loss: 0.0527 - val_mae: 0.1790\n",
      "Epoch 81/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0416 - mae: 0.1555 - val_loss: 0.0491 - val_mae: 0.1708\n",
      "Epoch 82/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0414 - mae: 0.1549 - val_loss: 0.0405 - val_mae: 0.1536\n",
      "Epoch 83/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0419 - mae: 0.1559 - val_loss: 0.0439 - val_mae: 0.1595\n",
      "Epoch 84/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0413 - mae: 0.1545 - val_loss: 0.0382 - val_mae: 0.1496\n",
      "Epoch 85/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0408 - mae: 0.1534 - val_loss: 0.0476 - val_mae: 0.1668\n",
      "Epoch 86/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0415 - mae: 0.1549 - val_loss: 0.0486 - val_mae: 0.1698\n",
      "Epoch 87/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0401 - mae: 0.1521 - val_loss: 0.0506 - val_mae: 0.1726\n",
      "Epoch 88/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0402 - mae: 0.1519 - val_loss: 0.0467 - val_mae: 0.1655\n",
      "Epoch 89/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0402 - mae: 0.1513 - val_loss: 0.0458 - val_mae: 0.1630\n",
      "Epoch 90/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0404 - mae: 0.1520 - val_loss: 0.0445 - val_mae: 0.1608\n",
      "Epoch 91/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0397 - mae: 0.1504 - val_loss: 0.0429 - val_mae: 0.1576\n",
      "Epoch 92/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0401 - mae: 0.1510 - val_loss: 0.0468 - val_mae: 0.1656\n",
      "Epoch 93/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0392 - mae: 0.1490 - val_loss: 0.0488 - val_mae: 0.1660\n",
      "Epoch 94/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0403 - mae: 0.1514 - val_loss: 0.0545 - val_mae: 0.1761\n",
      "Epoch 95/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0395 - mae: 0.1491 - val_loss: 0.0458 - val_mae: 0.1640\n",
      "Epoch 96/100\n",
      "13750/13750 [==============================] - 1s 52us/step - loss: 0.0395 - mae: 0.1494 - val_loss: 0.0500 - val_mae: 0.1692\n",
      "Epoch 97/100\n",
      "13750/13750 [==============================] - 1s 53us/step - loss: 0.0396 - mae: 0.1496 - val_loss: 0.0422 - val_mae: 0.1563\n",
      "Epoch 98/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0398 - mae: 0.1502 - val_loss: 0.0484 - val_mae: 0.1686\n",
      "Epoch 99/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0396 - mae: 0.1497 - val_loss: 0.0541 - val_mae: 0.1743\n",
      "Epoch 100/100\n",
      "13750/13750 [==============================] - 1s 54us/step - loss: 0.0390 - mae: 0.1486 - val_loss: 0.0525 - val_mae: 0.1742\n"
     ]
    }
   ],
   "source": [
    "HYPERPARAMETERS = {'depth': 6, 'width': 64, 'reduction_factor':  0.9}\n",
    "import tensorflow as tf\n",
    "with tf.device('/cpu:0'):\n",
    "    model = model_builder(9, 18)(**HYPERPARAMETERS)\n",
    "    hist = model.fit(x_train_1, q_train_1, epochs = 100, batch_size = 128, verbose = 1, validation_data=(IOD_x_test, IOD_q_test))\n",
    "    model.save(\"ik-rh5-leg-5steps_dropconnect_OOD.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch  = list(range(0, 200, 1))\n",
    "#print(epoch)\n",
    "#print(hist.history['loss'])\n",
    "# plt.figure()\n",
    "# plt.plot( epoch, hist.history['loss'],     label = 'Loss')\n",
    "# plt.plot( epoch, hist.history['mae'],      label = 'MAE')\n",
    "# plt.plot( epoch, hist.history['val_loss'], label = 'val_loss')\n",
    "# plt.plot( epoch, hist.history['val_mae'],  label = 'val_mae')\n",
    "# plt.xlabel(\"Number of Epochs\")\n",
    "# plt.ylabel(\"Error\")\n",
    "# plt.legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MAE: 0.17410\n",
      "Q feature 0 has unnorm MAE: 0.3621 (Range -0.7330 to 0.4398) normalized MAE: 0.3087\n",
      "Q feature 1 has unnorm MAE: 0.2945 (Range -0.3840 to 0.5792) normalized MAE: 0.3057\n",
      "Q feature 2 has unnorm MAE: 0.0909 (Range -0.8200 to -0.0680) normalized MAE: 0.1209\n",
      "Q feature 3 has unnorm MAE: 0.0925 (Range -0.8381 to -0.0792) normalized MAE: 0.1219\n",
      "Q feature 4 has unnorm MAE: 0.0102 (Range 0.0070 to 0.0907) normalized MAE: 0.1219\n",
      "Q feature 5 has unnorm MAE: 0.0429 (Range 0.0000 to 1.0000) normalized MAE: 0.0429\n",
      "Q feature 6 has unnorm MAE: 0.0033 (Range -0.0822 to 0.0000) normalized MAE: 0.0401\n",
      "Q feature 7 has unnorm MAE: 0.0036 (Range 0.0000 to 0.0782) normalized MAE: 0.0458\n",
      "Q feature 8 has unnorm MAE: 0.2997 (Range -0.7850 to 0.4710) normalized MAE: 0.2386\n",
      "Q feature 9 has unnorm MAE: 0.1827 (Range -0.7850 to 0.4710) normalized MAE: 0.1455\n",
      "Q feature 10 has unnorm MAE: 0.3129 (Range -0.5483 to 0.7767) normalized MAE: 0.2362\n",
      "Q feature 11 has unnorm MAE: 0.3325 (Range -0.5236 to 0.8523) normalized MAE: 0.2417\n",
      "Q feature 12 has unnorm MAE: 0.0419 (Range -0.0425 to 0.1199) normalized MAE: 0.2583\n",
      "Q feature 13 has unnorm MAE: 0.0165 (Range -0.0687 to 0.0186) normalized MAE: 0.1892\n",
      "Q feature 14 has unnorm MAE: 0.0199 (Range -0.0468 to 0.0678) normalized MAE: 0.1735\n",
      "Q feature 15 has unnorm MAE: 0.0377 (Range -0.0730 to 0.0783) normalized MAE: 0.2494\n",
      "Q feature 16 has unnorm MAE: 0.0184 (Range -0.0687 to 0.0249) normalized MAE: 0.1972\n",
      "Q feature 17 has unnorm MAE: 0.0105 (Range -0.0468 to 0.0625) normalized MAE: 0.0963\n"
     ]
    }
   ],
   "source": [
    "q_pred = model.predict(x_test, verbose=0)\n",
    "q_unnorm = q_scaler.inverse_transform(q_test)\n",
    "q_pred_unnorm = q_scaler.inverse_transform(q_pred)\n",
    "\n",
    "global_mae = mean_absolute_error(q_test, q_pred)\n",
    "\n",
    "print(\"Testing MAE: {:.5f}\".format(global_mae))\n",
    "\n",
    "# Compute MAE for each output independently.\n",
    "for i in range(q_test.shape[1]):\n",
    "    norm_mae_i = mean_absolute_error(q_test[:, i], q_pred[:, i])\n",
    "    mae_i = mean_absolute_error(q_unnorm[:, i], q_pred_unnorm[:, i])\n",
    "    print(\"Q feature {} has unnorm MAE: {:.4f} (Range {:.4f} to {:.4f}) normalized MAE: {:.4f}\".format(i, mae_i, q_scaler.data_min_[i], q_scaler.data_max_[i], norm_mae_i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MAE: 0.31371\n",
      "NLL: 13.86549\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras_uncertainty.models import MCDropoutRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def test_mcdropconnect_regressor(x_test_values, q_test_values, model, data_scaler):   \n",
    "    mc_model = MCDropoutRegressor(model)\n",
    "    inp = x_test_values  \n",
    "    \n",
    "    mean, std = mc_model.predict(inp, num_samples = 10)\n",
    "    \n",
    "    q_pred_unnormalised = data_scaler.inverse_transform(mean)\n",
    "    \n",
    "    #q_sd_unnromalised = data_scaler.inverse_transform(std)\n",
    "    \n",
    "    global_mae = mean_absolute_error(q_test_values, mean)\n",
    "\n",
    "    print(\"Testing MAE: {:.5f}\".format(global_mae))\n",
    "\n",
    "    return q_pred_unnormalised, std\n",
    "\n",
    "mean_1, std_1 = test_mcdropconnect_regressor(x_test, q_test, model, q_scaler)\n",
    "\n",
    "q_test_unorm = q_scaler.inverse_transform(q_test)\n",
    "\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_1, std_1**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MAE: 0.30525\n",
      "NLL: 14.30626\n"
     ]
    }
   ],
   "source": [
    "mean_test_IOD, sd_test_IOD = test_mcdropconnect_regressor(IOD_x_test, IOD_q_test, model, q_scaler)\n",
    "q_test_unorm = q_scaler.inverse_transform(IOD_q_test)\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_test_IOD, sd_test_IOD**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MAE: 0.43374\n",
      "NLL: 18.41770\n"
     ]
    }
   ],
   "source": [
    "mean_test_OOD, sd_test_OOD = test_mcdropconnect_regressor(OOD_x_test, OOD_q_test, model, q_scaler)\n",
    "q_test_unorm = q_scaler.inverse_transform(OOD_q_test)\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_test_OOD, sd_test_OOD**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_no = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sd_test_IOD_df = pd.DataFrame(sd_test_IOD)\n",
    "sd_test_OOD_df = pd.DataFrame(sd_test_OOD)\n",
    "new_scores = np.concatenate([sd_test_IOD_df[col_no], sd_test_OOD_df[col_no]], axis=0)\n",
    "minmaxscaler = MinMaxScaler()\n",
    "new_scores_scaled = minmaxscaler.fit_transform(new_scores.reshape(-1, 1))\n",
    "\n",
    "new_labels = np.concatenate([np.zeros_like(sd_test_IOD_df[col_no]), np.ones_like(sd_test_OOD_df[col_no])], axis=0)\n",
    "histogram_df = pd.DataFrame(new_scores_scaled, new_labels)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "a_heights, a_bins = np.histogram(sd_test_IOD_df[col_no].values.reshape(-1, 1), density=True)\n",
    "b_heights, b_bins = np.histogram(sd_test_OOD_df[col_no].values.reshape(-1, 1), bins=a_bins, density=True)\n",
    "\n",
    "width = (a_bins[1] - a_bins[0])/3\n",
    "\n",
    "ax.bar(a_bins[:-1], a_heights, width = width, facecolor='blue',label=\"IOD SD\")\n",
    "ax.bar(b_bins[:-1]+width, b_heights, width = width, facecolor='red', label=\"OOD SD\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Standard Deviation\")\n",
    "ax.set_ylabel(\"Normailsed density of Samples\")\n",
    "fig.savefig(\"density_vs_sd_dropconnect_sd_split_col_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.477294921875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "norm_scores = new_scores - min(new_scores) / (max(new_scores) - min(new_scores))\n",
    "\n",
    "auc = roc_auc_score(new_labels, new_scores)\n",
    "fpr, tpr, threshs = roc_curve(new_labels, norm_scores, drop_intermediate=True)\n",
    "print(auc)\n",
    "plt.xlabel('FPR', fontsize=13)\n",
    "plt.ylabel('TPR', fontsize=13)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.savefig(\"auc_dropconnect_sd_split_col_2.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
