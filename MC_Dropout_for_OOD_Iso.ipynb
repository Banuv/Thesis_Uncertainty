{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All imports #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys, os\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras\n",
    "import csv\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "\n",
    "from keras_uncertainty.models import MCDropoutClassifier, MCDropoutRegressor\n",
    "from keras_uncertainty.utils import numpy_regression_nll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_joint_space_csv_chunks(file_path):\n",
    "    data_frame = pd.read_csv(file_path, skiprows=1, header=None)\n",
    "    del data_frame[18]\n",
    "    return data_frame\n",
    "\n",
    "def load_task_space_csv_chunks(file_path):\n",
    "    return pd.read_csv(file_path, skiprows=1, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##please select the appropriate folder, willl use os.path.join() for completed script\n",
    "TRAIN_FOLDER = '/home/dfki.uni-bremen.de/bmanickavasakan/newdataset_rh5_leg/leg_15steps/'\n",
    "TEST_FOLDER = '/home/dfki.uni-bremen.de/bmanickavasakan/newdataset_rh5_leg/leg_15steps/test_14steps'\n",
    "\n",
    "X_TRAIN_FILE = os.path.join(TRAIN_FOLDER, 'leg_forwardkinematics_x.csv')\n",
    "Q_TRAIN_FILE = os.path.join(TRAIN_FOLDER, 'leg_sysstate_q.csv')\n",
    "x_train = load_task_space_csv_chunks(X_TRAIN_FILE)\n",
    "q_train = load_joint_space_csv_chunks(Q_TRAIN_FILE)\n",
    "\n",
    "X_TEST_FILE = os.path.join(TEST_FOLDER, 'leg_forwardkinematics_x.csv')\n",
    "Q_TEST_FILE = os.path.join(TEST_FOLDER, 'leg_sysstate_q.csv')\n",
    "x_test = load_task_space_csv_chunks(X_TEST_FILE)\n",
    "q_test = load_joint_space_csv_chunks(Q_TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_df = pd.DataFrame(x_train)\n",
    "q_train_df = pd.DataFrame(q_train)\n",
    "x_test_df = pd.DataFrame(x_test)\n",
    "q_test_df = pd.DataFrame(q_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "clf = IsolationForest(n_estimators=100, max_samples='auto', max_features=1, bootstrap=False, n_jobs= -1, random_state=42, verbose=0)\n",
    "clf.fit(q_train_df)\n",
    "\n",
    "pred = clf.predict(q_train_df)\n",
    "q_train_df['anamoly'] = pred\n",
    "print(q_train_df['anamoly'].value_counts())\n",
    "\n",
    "InDistribution_Q_Train = q_train_df[q_train_df['anamoly'] == 1]\n",
    "OutDistribution_Q_Train =   q_train_df[q_train_df['anamoly'] == -1]\n",
    "InDistribution_X_Train =    x_train_df[q_train_df['anamoly'] == 1]\n",
    "OutDistribution_X_Train =   x_train_df[q_train_df['anamoly'] == -1]\n",
    "\n",
    "clf_test = IsolationForest(n_estimators=100, max_samples='auto', max_features=1, bootstrap=False, n_jobs= -1, random_state=42, verbose=0)\n",
    "clf_test.fit(q_test_df)\n",
    "pred_test = clf.predict(q_test_df)\n",
    "q_test_df['anamoly'] = pred_test\n",
    "\n",
    "InDistribution_Q_Test = q_test_df[q_test_df['anamoly'] == 1]\n",
    "OutDistribution_Q_Test =q_test_df[q_test_df['anamoly'] == -1]\n",
    "InDistribution_X_Test = x_test_df[q_test_df['anamoly'] == 1]\n",
    "OutDistribution_X_Test =x_test_df[q_test_df['anamoly'] == -1]\n",
    "\n",
    "x_train_1 = InDistribution_X_Train\n",
    "q_train_1 = InDistribution_Q_Train.drop(['anamoly'], axis=1)\n",
    "x_test_1 = InDistribution_X_Test\n",
    "q_test_1 = InDistribution_Q_Test.drop(['anamoly'], axis=1)\n",
    "\n",
    "OOD_x_train = OutDistribution_X_Train\n",
    "OOD_q_train = OutDistribution_Q_Train.drop(['anamoly'], axis=1)\n",
    "OOD_x_test = OutDistribution_X_Test\n",
    "OOD_q_test = OutDistribution_Q_Test.drop(['anamoly'], axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model with MC Droput #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Standard deviation based data splitting\n",
    "\n",
    "We consider the Q features and use the feature with the \n",
    "\n",
    "highest SD for dividing the dataset\n",
    "'''\n",
    "'''\n",
    "stats_q_train = pd.DataFrame()\n",
    "stats_q_train[\"Mean\"] = q_train.mean()\n",
    "stats_q_train[\"Var\"] = q_train.var()\n",
    "stats_q_train[\"STD\"] = q_train.std()\n",
    "stats_q_train[\"OneSigmaMax\"] = stats_q_train[\"Mean\"] + stats_q_train[\"STD\"]\n",
    "stats_q_train[\"OneSigmaMin\"] = stats_q_train[\"Mean\"] - stats_q_train[\"STD\"]\n",
    "stats_q_train.T\n",
    "\n",
    "max_std = stats_q_train[\"STD\"].max()\n",
    "colomn_max_std = stats_q_train[\"STD\"].idxmax()\n",
    "\n",
    "maximum = stats_q_train.loc[colomn_max_std, \"Mean\"] + (1.5 * max_std)\n",
    "minimum = stats_q_train.loc[colomn_max_std, \"Mean\"] - (1.5 * max_std)\n",
    "print(maximum, minimum)\n",
    "\n",
    "InDistribution_Q_Train = q_train[q_train[colomn_max_std].le(maximum) & q_train[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_Q_Train = q_train[q_train[colomn_max_std].ge(maximum) | q_train[colomn_max_std].le(minimum)]\n",
    "InDistribution_X_Train = x_train[q_train[colomn_max_std].le(maximum) & q_train[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_X_Train = x_train[q_train[colomn_max_std].ge(maximum) | q_train[colomn_max_std].le(minimum)]\n",
    "\n",
    "InDistribution_Q_Test = q_test[q_test[colomn_max_std].le(maximum) & q_test[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_Q_Test = q_test[q_test[colomn_max_std].ge(maximum) | q_test[colomn_max_std].le(minimum)]\n",
    "InDistribution_X_Test = x_test[q_test[colomn_max_std].le(maximum) & q_test[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_X_Test = x_test[q_test[colomn_max_std].ge(maximum) | q_test[colomn_max_std].le(minimum)]\n",
    "\n",
    "x_train_1 = InDistribution_X_Train\n",
    "q_train_1 = InDistribution_Q_Train\n",
    "x_test_1 = InDistribution_X_Test\n",
    "q_test_1 = InDistribution_Q_Test\n",
    "\n",
    "OOD_x_train = OutDistribution_X_Train\n",
    "OOD_q_train = OutDistribution_Q_Train\n",
    "OOD_x_test = OutDistribution_X_Test\n",
    "OOD_q_test = OutDistribution_Q_Test\n",
    "\n",
    "print(\"//////////////////////\")\n",
    "print(x_train_1.shape, OOD_x_train.shape, x_test_1.shape, OOD_x_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "q_scaler = MinMaxScaler()\n",
    "\n",
    "#In order training set\n",
    "x_train_1 = x_scaler.fit_transform(x_train_1)\n",
    "q_train_1 = q_scaler.fit_transform(q_train_1)\n",
    "\n",
    "#complete test set\n",
    "x_test = x_scaler.transform(x_test)\n",
    "#q_test = q_scaler.transform(q_test)\n",
    "\n",
    "#split testing data\n",
    "IOD_x_test = x_scaler.transform(x_test_1)\n",
    "IOD_q_test = q_scaler.transform(q_test_1)\n",
    "\n",
    "OOD_x_test = x_scaler.transform(OOD_x_test)\n",
    "OOD_q_test = q_scaler.transform(OOD_q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(input_shape, output_shape):\n",
    "    def build_model(depth, width, reduction_factor):\n",
    "        model = Sequential()\n",
    "\n",
    "        for i in range(depth):\n",
    "            num_neurons = max(int(width * (reduction_factor ** i)), 4)\n",
    "            if i == 0:\n",
    "                model.add(Dense(num_neurons, activation='relu', input_shape=(input_shape,)))\n",
    "            else:\n",
    "                model.add(Dense(num_neurons, activation='relu'))\n",
    "                model.add(Dropout(0.5))\n",
    "\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Dense(output_shape, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=[\"mae\"])\n",
    "\n",
    "        return model\n",
    "    return build_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMETERS = {'depth': 6, 'width': 64, 'reduction_factor':  1.1}\n",
    "\n",
    "model = model_builder(9, 18)(**HYPERPARAMETERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device('/gpu:2'):\n",
    "    hist = model.fit(x_train_1, q_train_1, epochs = 50, batch_size = 16384, verbose = 1, validation_data=(IOD_x_test, IOD_q_test), use_multiprocessing=True, workers=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pred = model.predict(IOD_x_test, verbose=0)\n",
    "q_unnorm = q_scaler.inverse_transform(IOD_q_test)\n",
    "q_pred_unnorm = q_scaler.inverse_transform(q_pred)\n",
    "\n",
    "global_mae = mean_absolute_error(IOD_q_test, q_pred)\n",
    "mae_1 = mean_absolute_error(q_unnorm, q_pred_unnorm)\n",
    "\n",
    "print(\"Testing MAE: {:.5f}\".format(global_mae))\n",
    "print(\"Testing MAEX: {:.5f}\".format(mae_1))\n",
    "\n",
    "\n",
    "# Compute MAE for each output independently.\n",
    "for i in range(IOD_q_test.shape[1]):\n",
    "    norm_mae_i = mean_absolute_error(IOD_q_test[:, i], q_pred[:, i])\n",
    "    mae_i = mean_absolute_error(q_unnorm[:, i], q_pred_unnorm[:, i])\n",
    "    print(\"Q feature {} has unnorm MAE: {:.4f} (Range {:.4f} to {:.4f}) normalized MAE: {:.4f}\".format(i, mae_i, q_scaler.data_min_[i], q_scaler.data_max_[i], norm_mae_i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Dropout Regressor, O/P : mean, Std #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_mcdropout_regressor(x_test_values, q_test_values, model, data_scaler):   \n",
    "    mc_model = MCDropoutRegressor(model)\n",
    "    inp = x_test_values  \n",
    "    \n",
    "    mean, std = mc_model.predict(inp, num_samples = 10)\n",
    "    \n",
    "    q_pred_unnormalised = data_scaler.inverse_transform(mean)\n",
    "    \n",
    "    q_sd_unnromalised = data_scaler.inverse_transform(std)\n",
    "    \n",
    "    global_mae = mean_absolute_error(q_test_values, mean)\n",
    "\n",
    "    print(\"Testing MAE: {:.5f}\".format(global_mae))\n",
    "\n",
    "    return q_pred_unnormalised, q_sd_unnromalised\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mean_1, std_1 = test_mcdropout_regressor(x_test, q_test, model, q_scaler)\n",
    "\n",
    "q_test_unorm = q_scaler.inverse_transform(q_test)\n",
    "\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_1, std_1**2)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_test_IOD, sd_test_IOD = test_mcdropout_regressor(IOD_x_test, IOD_q_test, model, q_scaler)\n",
    "q_test_unorm = q_scaler.inverse_transform(IOD_q_test)\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_test_IOD, sd_test_IOD**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_OOD, sd_test_OOD = test_mcdropout_regressor(OOD_x_test, OOD_q_test, model, q_scaler)\n",
    "q_test_unorm = q_scaler.inverse_transform(OOD_q_test)\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_test_OOD, sd_test_OOD**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sd_test_IOD_df = pd.DataFrame(sd_test_IOD)\n",
    "sd_test_OOD_df = pd.DataFrame(sd_test_OOD)\n",
    "new_scores = np.concatenate([sd_test_IOD_df[0], sd_test_OOD_df[0]], axis=0)\n",
    "new_labels = np.concatenate([np.zeros_like(sd_test_IOD_df[0]), np.ones_like(sd_test_OOD_df[0])], axis=0)\n",
    "histogram_df = pd.DataFrame(new_scores, new_labels)\n",
    "print(new_scores.max())\n",
    "print(new_scores.min())\n",
    "#histogram_df.hist(column=0)\n",
    "\n",
    "#sd_test_IOD_df.hist(column=0)\n",
    "#sd_test_OOD_df.hist(column=0)\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "a_heights, a_bins = np.histogram(sd_test_IOD_df[0])\n",
    "b_heights, b_bins = np.histogram(sd_test_OOD_df[0], bins=a_bins)\n",
    "\n",
    "width = (a_bins[1] - a_bins[0])/3\n",
    "\n",
    "ax.bar(a_bins[:-1], a_heights, width = width, facecolor='blue',label=\"IOD SD\")\n",
    "ax.bar(b_bins[:-1]+width, b_heights, width = width, facecolor='red', label=\"OOD SD\")\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "norm_scores = new_scores - min(new_scores) / (max(new_scores) - min(new_scores))\n",
    "\n",
    "auc = roc_auc_score(new_labels, new_scores)\n",
    "fpr, tpr, threshs = roc_curve(new_labels, norm_scores, drop_intermediate=True)\n",
    "print(auc)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
