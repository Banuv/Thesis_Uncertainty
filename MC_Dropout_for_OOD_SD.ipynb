{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All imports #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras\n",
    "import csv\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "\n",
    "from keras_uncertainty.models import MCDropoutClassifier, MCDropoutRegressor\n",
    "from keras_uncertainty.utils import numpy_regression_nll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_joint_space_csv_chunks(file_path):\n",
    "    data_frame = pd.read_csv(file_path, skiprows=1, header=None)\n",
    "    del data_frame[18]\n",
    "    return data_frame\n",
    "\n",
    "def load_task_space_csv_chunks(file_path):\n",
    "    return pd.read_csv(file_path, skiprows=1, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##please select the appropriate folder, willl use os.path.join() for completed script\n",
    "TRAIN_FOLDER = '/home/dfki.uni-bremen.de/bmanickavasakan/newdataset_rh5_leg/leg_5steps/'\n",
    "TEST_FOLDER = '/home/dfki.uni-bremen.de/bmanickavasakan/newdataset_rh5_leg/leg_5steps/test_4steps'\n",
    "\n",
    "X_TRAIN_FILE = os.path.join(TRAIN_FOLDER, 'leg_forwardkinematics_x.csv')\n",
    "Q_TRAIN_FILE = os.path.join(TRAIN_FOLDER, 'leg_sysstate_q.csv')\n",
    "x_train = load_task_space_csv_chunks(X_TRAIN_FILE)\n",
    "q_train = load_joint_space_csv_chunks(Q_TRAIN_FILE)\n",
    "\n",
    "X_TEST_FILE = os.path.join(TEST_FOLDER, 'leg_forwardkinematics_x.csv')\n",
    "Q_TEST_FILE = os.path.join(TEST_FOLDER, 'leg_sysstate_q.csv')\n",
    "x_test = load_task_space_csv_chunks(X_TEST_FILE)\n",
    "q_test = load_joint_space_csv_chunks(Q_TEST_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model with MC Droput #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9119140506494964 -0.5558160506494813\n",
      "//////////////////////\n",
      "(13750, 9) (1875, 9) (3840, 9) (256, 9)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Standard deviation based data splitting\n",
    "\n",
    "We consider the Q features and use the feature with the \n",
    "\n",
    "highest SD for dividing the dataset\n",
    "'''\n",
    "\n",
    "stats_q_train = pd.DataFrame()\n",
    "stats_q_train[\"Mean\"] = q_train.mean()\n",
    "stats_q_train[\"Var\"] = q_train.var()\n",
    "stats_q_train[\"STD\"] = q_train.std()\n",
    "stats_q_train[\"OneSigmaMax\"] = stats_q_train[\"Mean\"] + stats_q_train[\"STD\"]\n",
    "stats_q_train[\"OneSigmaMin\"] = stats_q_train[\"Mean\"] - stats_q_train[\"STD\"]\n",
    "stats_q_train.T\n",
    "\n",
    "max_std = stats_q_train[\"STD\"].max()\n",
    "colomn_max_std = stats_q_train[\"STD\"].idxmax()\n",
    "\n",
    "maximum = stats_q_train.loc[colomn_max_std, \"Mean\"] + (1.5 * max_std)\n",
    "minimum = stats_q_train.loc[colomn_max_std, \"Mean\"] - (1.5 * max_std)\n",
    "print(maximum, minimum)\n",
    "\n",
    "InDistribution_Q_Train = q_train[q_train[colomn_max_std].le(maximum) & q_train[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_Q_Train = q_train[q_train[colomn_max_std].ge(maximum) | q_train[colomn_max_std].le(minimum)]\n",
    "InDistribution_X_Train = x_train[q_train[colomn_max_std].le(maximum) & q_train[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_X_Train = x_train[q_train[colomn_max_std].ge(maximum) | q_train[colomn_max_std].le(minimum)]\n",
    "\n",
    "InDistribution_Q_Test = q_test[q_test[colomn_max_std].le(maximum) & q_test[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_Q_Test = q_test[q_test[colomn_max_std].ge(maximum) | q_test[colomn_max_std].le(minimum)]\n",
    "InDistribution_X_Test = x_test[q_test[colomn_max_std].le(maximum) & q_test[colomn_max_std].ge(minimum)]\n",
    "OutDistribution_X_Test = x_test[q_test[colomn_max_std].ge(maximum) | q_test[colomn_max_std].le(minimum)]\n",
    "\n",
    "x_train_1 = InDistribution_X_Train\n",
    "q_train_1 = InDistribution_Q_Train\n",
    "x_test_1 = InDistribution_X_Test\n",
    "q_test_1 = InDistribution_Q_Test\n",
    "\n",
    "OOD_x_train = OutDistribution_X_Train\n",
    "OOD_q_train = OutDistribution_Q_Train\n",
    "OOD_x_test = OutDistribution_X_Test\n",
    "OOD_q_test = OutDistribution_Q_Test\n",
    "\n",
    "print(\"//////////////////////\")\n",
    "print(x_train_1.shape, OOD_x_train.shape, x_test_1.shape, OOD_x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "q_scaler = MinMaxScaler()\n",
    "\n",
    "#In order training set\n",
    "x_train_1 = x_scaler.fit_transform(x_train_1)\n",
    "q_train_1 = q_scaler.fit_transform(q_train_1)\n",
    "\n",
    "#complete test set\n",
    "x_test = x_scaler.transform(x_test)\n",
    "#q_test = q_scaler.transform(q_test)\n",
    "\n",
    "#split testing data\n",
    "IOD_x_test = x_scaler.transform(x_test_1)\n",
    "IOD_q_test = q_scaler.transform(q_test_1)\n",
    "\n",
    "OOD_x_test = x_scaler.transform(OOD_x_test)\n",
    "OOD_q_test = q_scaler.transform(OOD_q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(input_shape, output_shape):\n",
    "    def build_model(depth, width, reduction_factor):\n",
    "        model = Sequential()\n",
    "\n",
    "        for i in range(depth):\n",
    "            num_neurons = max(int(width * (reduction_factor ** i)), 4)\n",
    "            if i == 0:\n",
    "                model.add(Dense(num_neurons, activation='relu', input_shape=(input_shape,)))\n",
    "            else:\n",
    "                model.add(Dense(num_neurons, activation='relu'))\n",
    "                model.add(Dropout(0.5))\n",
    "\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Dense(output_shape, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='mse', optimizer='adam', metrics=[\"mae\"])\n",
    "\n",
    "        return model\n",
    "    return build_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "HYPERPARAMETERS = {'depth': 6, 'width': 64, 'reduction_factor':  1.1}\n",
    "#with tf.device('/cpu:0'):\n",
    "model = model_builder(9, 18)(**HYPERPARAMETERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13750 samples, validate on 3840 samples\n",
      "WARNING:tensorflow:From /home/dfki.uni-bremen.de/bmanickavasakan/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "13750/13750 [==============================] - 2s 122us/sample - loss: 0.1324 - mean_absolute_error: 0.2967 - val_loss: 0.1147 - val_mean_absolute_error: 0.2859\n",
      "Epoch 2/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0984 - mean_absolute_error: 0.2545 - val_loss: 0.1141 - val_mean_absolute_error: 0.2842\n",
      "Epoch 3/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0850 - mean_absolute_error: 0.2352 - val_loss: 0.0934 - val_mean_absolute_error: 0.2544\n",
      "Epoch 4/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0745 - mean_absolute_error: 0.2187 - val_loss: 0.0722 - val_mean_absolute_error: 0.2240\n",
      "Epoch 5/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0675 - mean_absolute_error: 0.2068 - val_loss: 0.0576 - val_mean_absolute_error: 0.1960\n",
      "Epoch 6/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0643 - mean_absolute_error: 0.2012 - val_loss: 0.0535 - val_mean_absolute_error: 0.1851\n",
      "Epoch 7/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0622 - mean_absolute_error: 0.1976 - val_loss: 0.0517 - val_mean_absolute_error: 0.1799\n",
      "Epoch 8/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0602 - mean_absolute_error: 0.1939 - val_loss: 0.0495 - val_mean_absolute_error: 0.1738\n",
      "Epoch 9/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0591 - mean_absolute_error: 0.1919 - val_loss: 0.0489 - val_mean_absolute_error: 0.1720\n",
      "Epoch 10/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0582 - mean_absolute_error: 0.1903 - val_loss: 0.0481 - val_mean_absolute_error: 0.1704\n",
      "Epoch 11/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0572 - mean_absolute_error: 0.1880 - val_loss: 0.0475 - val_mean_absolute_error: 0.1693\n",
      "Epoch 12/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0563 - mean_absolute_error: 0.1867 - val_loss: 0.0457 - val_mean_absolute_error: 0.1649\n",
      "Epoch 13/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0548 - mean_absolute_error: 0.1837 - val_loss: 0.0438 - val_mean_absolute_error: 0.1607\n",
      "Epoch 14/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0539 - mean_absolute_error: 0.1819 - val_loss: 0.0431 - val_mean_absolute_error: 0.1584\n",
      "Epoch 15/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0527 - mean_absolute_error: 0.1793 - val_loss: 0.0422 - val_mean_absolute_error: 0.1579\n",
      "Epoch 16/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0514 - mean_absolute_error: 0.1766 - val_loss: 0.0410 - val_mean_absolute_error: 0.1554\n",
      "Epoch 17/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0507 - mean_absolute_error: 0.1753 - val_loss: 0.0379 - val_mean_absolute_error: 0.1480\n",
      "Epoch 18/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0500 - mean_absolute_error: 0.1738 - val_loss: 0.0371 - val_mean_absolute_error: 0.1462\n",
      "Epoch 19/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0491 - mean_absolute_error: 0.1722 - val_loss: 0.0370 - val_mean_absolute_error: 0.1470\n",
      "Epoch 20/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0481 - mean_absolute_error: 0.1700 - val_loss: 0.0360 - val_mean_absolute_error: 0.1467\n",
      "Epoch 21/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0471 - mean_absolute_error: 0.1680 - val_loss: 0.0332 - val_mean_absolute_error: 0.1383\n",
      "Epoch 22/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0464 - mean_absolute_error: 0.1666 - val_loss: 0.0310 - val_mean_absolute_error: 0.1314\n",
      "Epoch 23/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0461 - mean_absolute_error: 0.1658 - val_loss: 0.0308 - val_mean_absolute_error: 0.1314\n",
      "Epoch 24/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0454 - mean_absolute_error: 0.1643 - val_loss: 0.0297 - val_mean_absolute_error: 0.1284\n",
      "Epoch 25/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0450 - mean_absolute_error: 0.1638 - val_loss: 0.0302 - val_mean_absolute_error: 0.1302\n",
      "Epoch 26/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0441 - mean_absolute_error: 0.1617 - val_loss: 0.0300 - val_mean_absolute_error: 0.1303\n",
      "Epoch 27/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0439 - mean_absolute_error: 0.1611 - val_loss: 0.0285 - val_mean_absolute_error: 0.1252\n",
      "Epoch 28/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0431 - mean_absolute_error: 0.1591 - val_loss: 0.0286 - val_mean_absolute_error: 0.1245\n",
      "Epoch 29/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0433 - mean_absolute_error: 0.1594 - val_loss: 0.0286 - val_mean_absolute_error: 0.1256\n",
      "Epoch 30/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0427 - mean_absolute_error: 0.1580 - val_loss: 0.0282 - val_mean_absolute_error: 0.1241\n",
      "Epoch 31/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0424 - mean_absolute_error: 0.1571 - val_loss: 0.0281 - val_mean_absolute_error: 0.1222\n",
      "Epoch 32/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0423 - mean_absolute_error: 0.1567 - val_loss: 0.0277 - val_mean_absolute_error: 0.1218\n",
      "Epoch 33/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0416 - mean_absolute_error: 0.1552 - val_loss: 0.0276 - val_mean_absolute_error: 0.1207\n",
      "Epoch 34/100\n",
      "13750/13750 [==============================] - 1s 57us/sample - loss: 0.0416 - mean_absolute_error: 0.1550 - val_loss: 0.0273 - val_mean_absolute_error: 0.1191\n",
      "Epoch 35/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0410 - mean_absolute_error: 0.1535 - val_loss: 0.0277 - val_mean_absolute_error: 0.1204\n",
      "Epoch 36/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0408 - mean_absolute_error: 0.1530 - val_loss: 0.0264 - val_mean_absolute_error: 0.1157\n",
      "Epoch 37/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0403 - mean_absolute_error: 0.1517 - val_loss: 0.0256 - val_mean_absolute_error: 0.1138\n",
      "Epoch 38/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0400 - mean_absolute_error: 0.1507 - val_loss: 0.0259 - val_mean_absolute_error: 0.1146\n",
      "Epoch 39/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0397 - mean_absolute_error: 0.1500 - val_loss: 0.0253 - val_mean_absolute_error: 0.1120\n",
      "Epoch 40/100\n",
      "13750/13750 [==============================] - 1s 57us/sample - loss: 0.0396 - mean_absolute_error: 0.1495 - val_loss: 0.0260 - val_mean_absolute_error: 0.1144\n",
      "Epoch 41/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0392 - mean_absolute_error: 0.1489 - val_loss: 0.0246 - val_mean_absolute_error: 0.1083\n",
      "Epoch 42/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0391 - mean_absolute_error: 0.1481 - val_loss: 0.0249 - val_mean_absolute_error: 0.1086\n",
      "Epoch 43/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0388 - mean_absolute_error: 0.1476 - val_loss: 0.0241 - val_mean_absolute_error: 0.1063\n",
      "Epoch 44/100\n",
      "13750/13750 [==============================] - 1s 57us/sample - loss: 0.0383 - mean_absolute_error: 0.1463 - val_loss: 0.0235 - val_mean_absolute_error: 0.1040\n",
      "Epoch 45/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0383 - mean_absolute_error: 0.1459 - val_loss: 0.0237 - val_mean_absolute_error: 0.1044\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0380 - mean_absolute_error: 0.1452 - val_loss: 0.0233 - val_mean_absolute_error: 0.1027\n",
      "Epoch 47/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0379 - mean_absolute_error: 0.1451 - val_loss: 0.0245 - val_mean_absolute_error: 0.1064\n",
      "Epoch 48/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0374 - mean_absolute_error: 0.1438 - val_loss: 0.0234 - val_mean_absolute_error: 0.1040\n",
      "Epoch 49/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0374 - mean_absolute_error: 0.1436 - val_loss: 0.0238 - val_mean_absolute_error: 0.1055\n",
      "Epoch 50/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0368 - mean_absolute_error: 0.1421 - val_loss: 0.0231 - val_mean_absolute_error: 0.1011\n",
      "Epoch 51/100\n",
      "13750/13750 [==============================] - 1s 53us/sample - loss: 0.0366 - mean_absolute_error: 0.1417 - val_loss: 0.0233 - val_mean_absolute_error: 0.1016\n",
      "Epoch 52/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0363 - mean_absolute_error: 0.1408 - val_loss: 0.0237 - val_mean_absolute_error: 0.1045\n",
      "Epoch 53/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0362 - mean_absolute_error: 0.1404 - val_loss: 0.0219 - val_mean_absolute_error: 0.0964\n",
      "Epoch 54/100\n",
      "13750/13750 [==============================] - 1s 63us/sample - loss: 0.0361 - mean_absolute_error: 0.1399 - val_loss: 0.0223 - val_mean_absolute_error: 0.0979\n",
      "Epoch 55/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0357 - mean_absolute_error: 0.1391 - val_loss: 0.0219 - val_mean_absolute_error: 0.0963\n",
      "Epoch 56/100\n",
      "13750/13750 [==============================] - 1s 63us/sample - loss: 0.0355 - mean_absolute_error: 0.1383 - val_loss: 0.0225 - val_mean_absolute_error: 0.0990\n",
      "Epoch 57/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0352 - mean_absolute_error: 0.1376 - val_loss: 0.0221 - val_mean_absolute_error: 0.0974\n",
      "Epoch 58/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0350 - mean_absolute_error: 0.1371 - val_loss: 0.0227 - val_mean_absolute_error: 0.0976\n",
      "Epoch 59/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0346 - mean_absolute_error: 0.1360 - val_loss: 0.0219 - val_mean_absolute_error: 0.0954\n",
      "Epoch 60/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0346 - mean_absolute_error: 0.1359 - val_loss: 0.0218 - val_mean_absolute_error: 0.0963\n",
      "Epoch 61/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0347 - mean_absolute_error: 0.1360 - val_loss: 0.0220 - val_mean_absolute_error: 0.0951\n",
      "Epoch 62/100\n",
      "13750/13750 [==============================] - 1s 63us/sample - loss: 0.0338 - mean_absolute_error: 0.1337 - val_loss: 0.0214 - val_mean_absolute_error: 0.0932\n",
      "Epoch 63/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0341 - mean_absolute_error: 0.1345 - val_loss: 0.0222 - val_mean_absolute_error: 0.0960\n",
      "Epoch 64/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0337 - mean_absolute_error: 0.1332 - val_loss: 0.0212 - val_mean_absolute_error: 0.0921\n",
      "Epoch 65/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0336 - mean_absolute_error: 0.1330 - val_loss: 0.0216 - val_mean_absolute_error: 0.0937\n",
      "Epoch 66/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0335 - mean_absolute_error: 0.1330 - val_loss: 0.0223 - val_mean_absolute_error: 0.0960\n",
      "Epoch 67/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0334 - mean_absolute_error: 0.1327 - val_loss: 0.0214 - val_mean_absolute_error: 0.0922\n",
      "Epoch 68/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0335 - mean_absolute_error: 0.1324 - val_loss: 0.0214 - val_mean_absolute_error: 0.0921\n",
      "Epoch 69/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0329 - mean_absolute_error: 0.1310 - val_loss: 0.0216 - val_mean_absolute_error: 0.0944\n",
      "Epoch 70/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0327 - mean_absolute_error: 0.1305 - val_loss: 0.0212 - val_mean_absolute_error: 0.0925\n",
      "Epoch 71/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0327 - mean_absolute_error: 0.1304 - val_loss: 0.0215 - val_mean_absolute_error: 0.0932\n",
      "Epoch 72/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0327 - mean_absolute_error: 0.1303 - val_loss: 0.0222 - val_mean_absolute_error: 0.0950\n",
      "Epoch 73/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0326 - mean_absolute_error: 0.1300 - val_loss: 0.0214 - val_mean_absolute_error: 0.0917\n",
      "Epoch 74/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0326 - mean_absolute_error: 0.1300 - val_loss: 0.0225 - val_mean_absolute_error: 0.0984\n",
      "Epoch 75/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0324 - mean_absolute_error: 0.1296 - val_loss: 0.0224 - val_mean_absolute_error: 0.0965\n",
      "Epoch 76/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0325 - mean_absolute_error: 0.1296 - val_loss: 0.0211 - val_mean_absolute_error: 0.0903\n",
      "Epoch 77/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0321 - mean_absolute_error: 0.1285 - val_loss: 0.0217 - val_mean_absolute_error: 0.0946\n",
      "Epoch 78/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0322 - mean_absolute_error: 0.1287 - val_loss: 0.0214 - val_mean_absolute_error: 0.0925\n",
      "Epoch 79/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0319 - mean_absolute_error: 0.1280 - val_loss: 0.0220 - val_mean_absolute_error: 0.0960\n",
      "Epoch 80/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0319 - mean_absolute_error: 0.1281 - val_loss: 0.0217 - val_mean_absolute_error: 0.0935\n",
      "Epoch 81/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0318 - mean_absolute_error: 0.1275 - val_loss: 0.0215 - val_mean_absolute_error: 0.0927\n",
      "Epoch 82/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0318 - mean_absolute_error: 0.1275 - val_loss: 0.0208 - val_mean_absolute_error: 0.0892\n",
      "Epoch 83/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0320 - mean_absolute_error: 0.1278 - val_loss: 0.0210 - val_mean_absolute_error: 0.0908\n",
      "Epoch 84/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0317 - mean_absolute_error: 0.1274 - val_loss: 0.0219 - val_mean_absolute_error: 0.0955\n",
      "Epoch 85/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0313 - mean_absolute_error: 0.1262 - val_loss: 0.0213 - val_mean_absolute_error: 0.0930\n",
      "Epoch 86/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0314 - mean_absolute_error: 0.1265 - val_loss: 0.0219 - val_mean_absolute_error: 0.0946\n",
      "Epoch 87/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0313 - mean_absolute_error: 0.1261 - val_loss: 0.0208 - val_mean_absolute_error: 0.0905\n",
      "Epoch 88/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0314 - mean_absolute_error: 0.1262 - val_loss: 0.0211 - val_mean_absolute_error: 0.0908\n",
      "Epoch 89/100\n",
      "13750/13750 [==============================] - 1s 60us/sample - loss: 0.0312 - mean_absolute_error: 0.1258 - val_loss: 0.0216 - val_mean_absolute_error: 0.0932\n",
      "Epoch 90/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0314 - mean_absolute_error: 0.1260 - val_loss: 0.0213 - val_mean_absolute_error: 0.0929\n",
      "Epoch 91/100\n",
      "13750/13750 [==============================] - 1s 59us/sample - loss: 0.0311 - mean_absolute_error: 0.1252 - val_loss: 0.0221 - val_mean_absolute_error: 0.0967\n",
      "Epoch 92/100\n",
      "13750/13750 [==============================] - 1s 58us/sample - loss: 0.0314 - mean_absolute_error: 0.1260 - val_loss: 0.0218 - val_mean_absolute_error: 0.0948\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0310 - mean_absolute_error: 0.1250 - val_loss: 0.0210 - val_mean_absolute_error: 0.0907\n",
      "Epoch 94/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0310 - mean_absolute_error: 0.1250 - val_loss: 0.0213 - val_mean_absolute_error: 0.0924\n",
      "Epoch 95/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0308 - mean_absolute_error: 0.1247 - val_loss: 0.0207 - val_mean_absolute_error: 0.0892\n",
      "Epoch 96/100\n",
      "13750/13750 [==============================] - 1s 63us/sample - loss: 0.0308 - mean_absolute_error: 0.1246 - val_loss: 0.0214 - val_mean_absolute_error: 0.0923\n",
      "Epoch 97/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0309 - mean_absolute_error: 0.1248 - val_loss: 0.0217 - val_mean_absolute_error: 0.0929\n",
      "Epoch 98/100\n",
      "13750/13750 [==============================] - 1s 61us/sample - loss: 0.0309 - mean_absolute_error: 0.1247 - val_loss: 0.0211 - val_mean_absolute_error: 0.0901\n",
      "Epoch 99/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0309 - mean_absolute_error: 0.1246 - val_loss: 0.0219 - val_mean_absolute_error: 0.0955\n",
      "Epoch 100/100\n",
      "13750/13750 [==============================] - 1s 62us/sample - loss: 0.0307 - mean_absolute_error: 0.1240 - val_loss: 0.0210 - val_mean_absolute_error: 0.0915\n"
     ]
    }
   ],
   "source": [
    "#with tf.device('/cpu:0'):\n",
    "hist = model.fit(x_train_1, q_train_1, epochs = 100, batch_size = 128, verbose = 1, validation_data=(IOD_x_test, IOD_q_test))\n",
    "#use_multiprocessing=True, workers=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MAE: 0.09150\n",
      "Testing MAEX: 0.06371\n",
      "Q feature 0 has unnorm MAE: 0.3670 (Range -0.7330 to 0.4398) normalized MAE: 0.3129\n",
      "Q feature 1 has unnorm MAE: 0.3008 (Range -0.3840 to 0.5792) normalized MAE: 0.3123\n",
      "Q feature 2 has unnorm MAE: 0.0317 (Range -0.8200 to -0.0680) normalized MAE: 0.0421\n",
      "Q feature 3 has unnorm MAE: 0.0319 (Range -0.8381 to -0.0792) normalized MAE: 0.0421\n",
      "Q feature 4 has unnorm MAE: 0.0035 (Range 0.0070 to 0.0907) normalized MAE: 0.0419\n",
      "Q feature 5 has unnorm MAE: 0.0732 (Range 0.0000 to 1.0000) normalized MAE: 0.0732\n",
      "Q feature 6 has unnorm MAE: 0.0030 (Range -0.0822 to 0.0000) normalized MAE: 0.0369\n",
      "Q feature 7 has unnorm MAE: 0.0059 (Range 0.0000 to 0.0782) normalized MAE: 0.0760\n",
      "Q feature 8 has unnorm MAE: 0.0571 (Range -0.7850 to 0.4710) normalized MAE: 0.0455\n",
      "Q feature 9 has unnorm MAE: 0.0857 (Range -0.7850 to 0.4710) normalized MAE: 0.0682\n",
      "Q feature 10 has unnorm MAE: 0.0610 (Range -0.5483 to 0.7767) normalized MAE: 0.0460\n",
      "Q feature 11 has unnorm MAE: 0.0672 (Range -0.5236 to 0.8523) normalized MAE: 0.0488\n",
      "Q feature 12 has unnorm MAE: 0.0120 (Range -0.0425 to 0.1199) normalized MAE: 0.0740\n",
      "Q feature 13 has unnorm MAE: 0.0093 (Range -0.0687 to 0.0186) normalized MAE: 0.1066\n",
      "Q feature 14 has unnorm MAE: 0.0068 (Range -0.0468 to 0.0678) normalized MAE: 0.0590\n",
      "Q feature 15 has unnorm MAE: 0.0136 (Range -0.0730 to 0.0783) normalized MAE: 0.0901\n",
      "Q feature 16 has unnorm MAE: 0.0108 (Range -0.0687 to 0.0249) normalized MAE: 0.1159\n",
      "Q feature 17 has unnorm MAE: 0.0060 (Range -0.0468 to 0.0625) normalized MAE: 0.0552\n"
     ]
    }
   ],
   "source": [
    "q_pred = model.predict(IOD_x_test, verbose=0)\n",
    "q_unnorm = q_scaler.inverse_transform(IOD_q_test)\n",
    "q_pred_unnorm = q_scaler.inverse_transform(q_pred)\n",
    "\n",
    "global_mae = mean_absolute_error(IOD_q_test, q_pred)\n",
    "mae_1 = mean_absolute_error(q_unnorm, q_pred_unnorm)\n",
    "\n",
    "print(\"Testing MAE: {:.5f}\".format(global_mae))\n",
    "print(\"Testing MAEX: {:.5f}\".format(mae_1))\n",
    "\n",
    "\n",
    "# Compute MAE for each output independently.\n",
    "for i in range(IOD_q_test.shape[1]):\n",
    "    norm_mae_i = mean_absolute_error(IOD_q_test[:, i], q_pred[:, i])\n",
    "    mae_i = mean_absolute_error(q_unnorm[:, i], q_pred_unnorm[:, i])\n",
    "    print(\"Q feature {} has unnorm MAE: {:.4f} (Range {:.4f} to {:.4f}) normalized MAE: {:.4f}\".format(i, mae_i, q_scaler.data_min_[i], q_scaler.data_max_[i], norm_mae_i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Dropout Regressor, O/P : mean, Std #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_mcdropout_regressor(x_test_values, q_test_values, model, data_scaler):   \n",
    "    mc_model = MCDropoutRegressor(model)\n",
    "    inp = x_test_values  \n",
    "    \n",
    "    mean, std = mc_model.predict(inp, num_samples = 10)\n",
    "    \n",
    "    q_pred_unnormalised = data_scaler.inverse_transform(mean)\n",
    "    \n",
    "    q_sd_unnromalised = data_scaler.inverse_transform(std)\n",
    "    \n",
    "    global_mae = mean_absolute_error(q_test_values, mean)\n",
    "\n",
    "    print(\"Testing MAE: {:.5f}\".format(global_mae))\n",
    "\n",
    "    return q_pred_unnormalised, q_sd_unnromalised\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmean_1, std_1 = test_mcdropout_regressor(x_test, q_test, model, q_scaler)\\n\\nq_test_unorm = q_scaler.inverse_transform(q_test)\\n\\nprint(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_1, std_1**2)))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "mean_1, std_1 = test_mcdropout_regressor(x_test, q_test, model, q_scaler)\n",
    "\n",
    "q_test_unorm = q_scaler.inverse_transform(q_test)\n",
    "\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_1, std_1**2)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MAE: 0.30540\n",
      "NLL: 31.11246\n"
     ]
    }
   ],
   "source": [
    "mean_test_IOD, sd_test_IOD = test_mcdropout_regressor(IOD_x_test, IOD_q_test, model, q_scaler)\n",
    "q_test_unorm = q_scaler.inverse_transform(IOD_q_test)\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_test_IOD, sd_test_IOD**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MAE: 0.43475\n",
      "NLL: 25.34822\n"
     ]
    }
   ],
   "source": [
    "mean_test_OOD, sd_test_OOD = test_mcdropout_regressor(OOD_x_test, OOD_q_test, model, q_scaler)\n",
    "q_test_unorm = q_scaler.inverse_transform(OOD_q_test)\n",
    "print(\"NLL: {:.5f}\".format(numpy_regression_nll(q_test_unorm, mean_test_OOD, sd_test_OOD**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.72872216 -0.67601234 -0.7245667 -0.68110555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1ee06f5978>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ee070b908>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sd_test_IOD_df = pd.DataFrame(sd_test_IOD)\n",
    "sd_test_OOD_df = pd.DataFrame(sd_test_OOD)\n",
    "new_scores = np.concatenate([sd_test_IOD_df[0], sd_test_OOD_df[0]], axis=0)\n",
    "new_labels = np.concatenate([np.zeros_like(sd_test_IOD_df[0]), np.ones_like(sd_test_OOD_df[0])], axis=0)\n",
    "histogram_df = pd.DataFrame(new_scores, new_labels)\n",
    "#print(new_scores.max())\n",
    "#print(new_scores.min())\n",
    "print(sd_test_IOD_df[0].min(), sd_test_IOD_df[0].max(), sd_test_OOD_df[0].min(), sd_test_OOD_df[0].max())\n",
    "#histogram_df.hist(column=0)\n",
    "\n",
    "#sd_test_IOD_df.hist(column=0)\n",
    "#sd_test_OOD_df.hist(column=0)\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "a_heights, a_bins = np.histogram(sd_test_IOD_df[0])\n",
    "b_heights, b_bins = np.histogram(sd_test_OOD_df[0], bins=a_bins)\n",
    "\n",
    "width = (a_bins[1] - a_bins[0])/3\n",
    "\n",
    "ax.bar(a_bins[:-1], a_heights, width = width, facecolor='blue',label=\"IOD SD\")\n",
    "ax.bar(b_bins[:-1]+width, b_heights, width = width, facecolor='red', label=\"OOD SD\")\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "norm_scores = new_scores - min(new_scores) / (max(new_scores) - min(new_scores))\n",
    "\n",
    "auc = roc_auc_score(new_labels, new_scores)\n",
    "fpr, tpr, threshs = roc_curve(new_labels, norm_scores, drop_intermediate=True)\n",
    "print(auc)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
